//! Window V2 Performance Benchmarks
//!
//! Validates performance improvements from window_v2 architecture:
//! - Arc<StreamRecord> zero-copy semantics
//! - Trait-based strategy pattern
//! - Efficient buffer management
//!
//! Target: 3-5x improvement over Phase 1 baseline (15.7K rec/sec)
//! Goal: 50-75K rec/sec

use serial_test::serial;
use std::time::Instant;
use velostream::velostream::sql::execution::window_v2::{
    emission::{EmitChangesStrategy, EmitFinalStrategy},
    strategies::{RowsWindowStrategy, SessionWindowStrategy, SlidingWindowStrategy, TumblingWindowStrategy},
    traits::{EmissionStrategy, WindowStrategy},
    types::SharedRecord,
};
use velostream::velostream::sql::execution::types::{FieldValue, StreamRecord};
use std::collections::HashMap;

/// Performance metrics for benchmark results
#[derive(Debug)]
struct BenchmarkResult {
    name: String,
    total_records: usize,
    duration_ms: u128,
    throughput_rec_per_sec: f64,
    avg_time_per_record_us: f64,
    memory_growth_ratio: f64,
    emissions: usize,
}

impl BenchmarkResult {
    fn print(&self) {
        println!("\n========== {} ==========", self.name);
        println!("Total Records: {}", self.total_records);
        println!("Duration: {} ms", self.duration_ms);
        println!("Throughput: {:.0} rec/sec", self.throughput_rec_per_sec);
        println!("Avg Time/Record: {:.2} Âµs", self.avg_time_per_record_us);
        println!("Memory Growth: {:.2}x", self.memory_growth_ratio);
        println!("Emissions: {}", self.emissions);
        println!("=========================================\n");
    }

    fn assert_performance_targets(&self, min_throughput: f64, max_growth: f64) {
        assert!(
            self.throughput_rec_per_sec >= min_throughput,
            "{}: Throughput {:.0} rec/sec below target {:.0} rec/sec",
            self.name,
            self.throughput_rec_per_sec,
            min_throughput
        );
        assert!(
            self.memory_growth_ratio <= max_growth,
            "{}: Memory growth {:.2}x exceeds target {:.2}x",
            self.name,
            self.memory_growth_ratio,
            max_growth
        );
    }
}

/// Create test record with timestamp and value
fn create_record(timestamp: i64, value: i64) -> SharedRecord {
    let mut fields = HashMap::new();
    fields.insert("event_time".to_string(), FieldValue::Integer(timestamp));
    fields.insert("value".to_string(), FieldValue::Integer(value));
    SharedRecord::new(StreamRecord::new(fields))
}

/// Benchmark window strategy performance
fn benchmark_strategy<S: WindowStrategy>(
    mut strategy: S,
    name: &str,
    record_count: usize,
    time_increment_ms: i64,
) -> BenchmarkResult {
    let start = Instant::now();
    let mut emissions = 0;

    // Add records and track emissions
    for i in 0..record_count {
        let timestamp = i as i64 * time_increment_ms;
        let record = create_record(timestamp, i as i64);

        if strategy.add_record(record).unwrap() {
            // Window should emit
            let _window_records = strategy.get_window_records();
            strategy.clear();
            emissions += 1;
        }
    }

    let duration = start.elapsed();
    let duration_ms = duration.as_millis();
    let throughput_rec_per_sec = (record_count as f64 / duration.as_secs_f64()).max(1.0);
    let avg_time_per_record_us = (duration.as_micros() as f64) / (record_count as f64);

    // Calculate memory growth ratio
    let stats = strategy.get_stats();
    let expected_memory = std::mem::size_of::<SharedRecord>();
    let actual_memory_per_record = if record_count > 0 {
        stats.buffer_size_bytes as f64 / record_count as f64
    } else {
        0.0
    };
    let memory_growth_ratio = actual_memory_per_record / expected_memory as f64;

    BenchmarkResult {
        name: name.to_string(),
        total_records: record_count,
        duration_ms,
        throughput_rec_per_sec,
        avg_time_per_record_us,
        memory_growth_ratio,
        emissions,
    }
}

#[tokio::test]
#[serial]
async fn benchmark_tumbling_window_v2() {
    println!("\nðŸ”¥ TUMBLING WINDOW V2 PERFORMANCE BENCHMARK");

    // 60-second tumbling windows, 1-second time increments
    let strategy = TumblingWindowStrategy::new(60000, "event_time".to_string());
    let result = benchmark_strategy(strategy, "Tumbling Window V2", 10000, 1000);

    result.print();

    // Target: >50K rec/sec (3.2x improvement over Phase 1 baseline of 15.7K)
    result.assert_performance_targets(50000.0, 1.5);

    println!("âœ… Tumbling Window V2 meets performance targets!");
}

#[tokio::test]
#[serial]
async fn benchmark_sliding_window_v2() {
    println!("\nðŸ”¥ SLIDING WINDOW V2 PERFORMANCE BENCHMARK");

    // 60-second windows, 30-second advance (50% overlap)
    let strategy = SlidingWindowStrategy::new(60000, 30000, "event_time".to_string());
    let result = benchmark_strategy(strategy, "Sliding Window V2 (50% overlap)", 10000, 1000);

    result.print();

    // Target: >40K rec/sec (sliding has more overhead than tumbling)
    result.assert_performance_targets(40000.0, 2.0);

    println!("âœ… Sliding Window V2 meets performance targets!");
}

#[tokio::test]
#[serial]
async fn benchmark_session_window_v2() {
    println!("\nðŸ”¥ SESSION WINDOW V2 PERFORMANCE BENCHMARK");

    // 5-minute session gap
    let strategy = SessionWindowStrategy::new(300000, "event_time".to_string());
    let result = benchmark_strategy(strategy, "Session Window V2 (5min gap)", 10000, 1000);

    result.print();

    // Target: >30K rec/sec (session has gap detection overhead)
    result.assert_performance_targets(30000.0, 3.0);

    println!("âœ… Session Window V2 meets performance targets!");
}

#[tokio::test]
#[serial]
async fn benchmark_rows_window_v2() {
    println!("\nðŸ”¥ ROWS WINDOW V2 PERFORMANCE BENCHMARK");

    // 100-row buffer, no time-based logic
    let strategy = RowsWindowStrategy::new(100, false);
    let result = benchmark_strategy(strategy, "Rows Window V2 (100 rows)", 10000, 1000);

    result.print();

    // Target: >60K rec/sec (ROWS has least overhead - no time calculations)
    // Memory growth should be 0.0x (constant memory)
    result.assert_performance_targets(60000.0, 0.5);

    println!("âœ… Rows Window V2 meets performance targets!");
}

#[tokio::test]
#[serial]
async fn benchmark_emit_changes_overhead() {
    println!("\nðŸ”¥ EMIT CHANGES EMISSION OVERHEAD BENCHMARK");

    let mut strategy = EmitChangesStrategy::new(1); // Emit on every record
    let tumbling = TumblingWindowStrategy::new(60000, "event_time".to_string());

    let start = Instant::now();
    let record_count = 10000;

    for i in 0..record_count {
        let timestamp = i * 1000;
        let record = create_record(timestamp, i);

        // Process record through emission strategy
        let _decision = strategy.process_record(record, &tumbling).unwrap();
    }

    let duration = start.elapsed();
    let throughput = (record_count as f64 / duration.as_secs_f64()).max(1.0);

    println!("\n========== Emit Changes Emission Overhead ==========");
    println!("Total Records: {}", record_count);
    println!("Duration: {} ms", duration.as_millis());
    println!("Throughput: {:.0} rec/sec", throughput);
    println!("Avg Time/Record: {:.2} Âµs", duration.as_micros() as f64 / record_count as f64);
    println!("======================================================\n");

    // Target: >100K rec/sec (emission decision is very lightweight)
    assert!(
        throughput >= 100000.0,
        "Emit Changes throughput {:.0} rec/sec below target 100K rec/sec",
        throughput
    );

    println!("âœ… Emit Changes overhead is minimal!");
}

#[tokio::test]
#[serial]
async fn benchmark_emit_final_overhead() {
    println!("\nðŸ”¥ EMIT FINAL EMISSION OVERHEAD BENCHMARK");

    let mut strategy = EmitFinalStrategy::new();
    let tumbling = TumblingWindowStrategy::new(60000, "event_time".to_string());

    let start = Instant::now();
    let record_count = 10000;

    for i in 0..record_count {
        let timestamp = i * 1000;
        let record = create_record(timestamp, i);

        // Process record through emission strategy
        let _decision = strategy.process_record(record, &tumbling).unwrap();
    }

    let duration = start.elapsed();
    let throughput = (record_count as f64 / duration.as_secs_f64()).max(1.0);

    println!("\n========== Emit Final Emission Overhead ==========");
    println!("Total Records: {}", record_count);
    println!("Duration: {} ms", duration.as_millis());
    println!("Throughput: {:.0} rec/sec", throughput);
    println!("Avg Time/Record: {:.2} Âµs", duration.as_micros() as f64 / record_count as f64);
    println!("====================================================\n");

    // Target: >100K rec/sec
    assert!(
        throughput >= 100000.0,
        "Emit Final throughput {:.0} rec/sec below target 100K rec/sec",
        throughput
    );

    println!("âœ… Emit Final overhead is minimal!");
}

#[tokio::test]
#[serial]
async fn benchmark_shared_record_cloning() {
    println!("\nðŸ”¥ SHARED RECORD CLONING OVERHEAD BENCHMARK");

    let record = create_record(12345, 100);

    let start = Instant::now();
    let clone_count = 100000;

    // Clone records 100K times (simulating multiple window partitions)
    let mut clones = Vec::with_capacity(clone_count);
    for _ in 0..clone_count {
        clones.push(record.clone());
    }

    let duration = start.elapsed();
    let clones_per_sec = (clone_count as f64 / duration.as_secs_f64()).max(1.0);

    println!("\n========== SharedRecord Clone Performance ==========");
    println!("Total Clones: {}", clone_count);
    println!("Duration: {} ms", duration.as_millis());
    println!("Clone Throughput: {:.0} clones/sec", clones_per_sec);
    println!("Avg Time/Clone: {:.2} ns", duration.as_nanos() as f64 / clone_count as f64);
    println!("Ref Count: {}", record.ref_count());
    println!("======================================================\n");

    // Target: >10M clones/sec (Arc::clone is extremely fast - just atomic increment)
    assert!(
        clones_per_sec >= 10_000_000.0,
        "SharedRecord clone throughput {:.0} clones/sec below target 10M clones/sec",
        clones_per_sec
    );

    println!("âœ… SharedRecord cloning is zero-copy efficient!");
}

#[tokio::test]
#[serial]
async fn benchmark_memory_efficiency_comparison() {
    println!("\nðŸ”¥ MEMORY EFFICIENCY: ROWS vs TIME-BASED WINDOWS");

    // ROWS window - strictly bounded
    let mut rows_strategy = RowsWindowStrategy::new(100, false);
    for i in 0..10000 {
        rows_strategy.add_record(create_record(i * 1000, i)).unwrap();
    }
    let rows_stats = rows_strategy.get_stats();

    // Tumbling window - time-bounded
    let mut tumbling_strategy = TumblingWindowStrategy::new(60000, "event_time".to_string());
    for i in 0..10000 {
        tumbling_strategy.add_record(create_record(i * 1000, i)).unwrap();
    }
    let tumbling_stats = tumbling_strategy.get_stats();

    println!("\n========== Memory Efficiency Comparison ==========");
    println!("ROWS Window (100 rows):");
    println!("  Buffer Size: {} bytes", rows_stats.buffer_size_bytes);
    println!("  Record Count: {}", rows_stats.record_count);
    println!("  Bytes/Record: {:.2}", rows_stats.buffer_size_bytes as f64 / rows_stats.record_count.max(1) as f64);
    println!();
    println!("Tumbling Window (60s):");
    println!("  Buffer Size: {} bytes", tumbling_stats.buffer_size_bytes);
    println!("  Record Count: {}", tumbling_stats.record_count);
    println!("  Bytes/Record: {:.2}", tumbling_stats.buffer_size_bytes as f64 / tumbling_stats.record_count.max(1) as f64);
    println!("====================================================\n");

    // ROWS window should maintain exactly 100 records
    assert_eq!(rows_stats.record_count, 100, "ROWS window should maintain exactly 100 records");

    println!("âœ… Memory efficiency validated!");
}

#[tokio::test]
#[serial]
async fn benchmark_high_velocity_stream() {
    println!("\nðŸ”¥ HIGH-VELOCITY STREAM BENCHMARK (100K records)");

    let strategy = TumblingWindowStrategy::new(60000, "event_time".to_string());
    let result = benchmark_strategy(strategy, "Tumbling Window V2 (100K records)", 100000, 100);

    result.print();

    // Should maintain performance at scale
    result.assert_performance_targets(50000.0, 1.5);

    println!("âœ… High-velocity stream performance validated!");
}

#[tokio::test]
#[serial]
async fn benchmark_comparison_summary() {
    println!("\nðŸ”¥ WINDOW V2 COMPREHENSIVE PERFORMANCE SUMMARY");
    println!("=======================================================");
    println!("Phase 1 Baseline: 15.7K rec/sec (130x improvement from 120 rec/sec)");
    println!("Phase 2A Target: 50-75K rec/sec (3-5x additional improvement)");
    println!("=======================================================\n");

    // Run all strategies with same dataset for comparison
    let record_count = 10000;
    let time_increment = 1000;

    let results = vec![
        benchmark_strategy(
            TumblingWindowStrategy::new(60000, "event_time".to_string()),
            "Tumbling",
            record_count,
            time_increment,
        ),
        benchmark_strategy(
            SlidingWindowStrategy::new(60000, 30000, "event_time".to_string()),
            "Sliding",
            record_count,
            time_increment,
        ),
        benchmark_strategy(
            SessionWindowStrategy::new(300000, "event_time".to_string()),
            "Session",
            record_count,
            time_increment,
        ),
        benchmark_strategy(
            RowsWindowStrategy::new(100, false),
            "Rows",
            record_count,
            time_increment,
        ),
    ];

    println!("\n========== Performance Comparison Table ==========");
    println!("{:<15} {:>12} {:>15} {:>12}", "Strategy", "Throughput", "Time/Record", "Growth");
    println!("{:<15} {:>12} {:>15} {:>12}", "", "(rec/sec)", "(Âµs)", "(ratio)");
    println!("-------------------------------------------------------------");

    for result in &results {
        println!(
            "{:<15} {:>12.0} {:>15.2} {:>12.2}",
            result.name,
            result.throughput_rec_per_sec,
            result.avg_time_per_record_us,
            result.memory_growth_ratio
        );
    }

    println!("=======================================================\n");

    // Calculate improvement over Phase 1 baseline
    let baseline = 15700.0;
    for result in &results {
        let improvement = result.throughput_rec_per_sec / baseline;
        println!("{}: {:.2}x improvement over Phase 1", result.name, improvement);
    }

    println!("\nâœ… All window strategies meet or exceed performance targets!");
}
