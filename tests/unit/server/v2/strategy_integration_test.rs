//! Integration tests for PartitioningStrategy with AdaptiveJobProcessor
//!
//! Tests the complete flow of strategy-based record routing:
//! - Strategy selection and configuration
//! - Record routing consistency
//! - State consistency guarantees (same GROUP BY key â†’ same partition)
//! - Error handling and validation

use std::collections::HashMap;
use std::sync::Arc;
use velostream::velostream::serialization::FieldValue;
use velostream::velostream::server::v2::{
    AdaptiveJobProcessor, AlwaysHashStrategy, FanInStrategy, PartitionedJobConfig,
    PartitioningStrategy, QueryMetadata, RoundRobinStrategy, RoutingContext,
    SmartRepartitionStrategy, StickyPartitionStrategy, StrategyConfig, StrategyFactory,
};
use velostream::velostream::sql::execution::types::StreamRecord;

/// Test basic strategy configuration with coordinator
#[test]
fn test_coordinator_with_always_hash_strategy() {
    let config = PartitionedJobConfig::default();
    let coordinator = AdaptiveJobProcessor::new(config)
        .with_group_by_columns(vec!["trader_id".to_string()])
        .with_strategy(Arc::new(AlwaysHashStrategy::new()));

    assert_eq!(coordinator.num_partitions(), num_cpus::get().max(1));
}

/// Test strategy validation with GROUP BY columns
#[test]
fn test_strategy_validation_with_group_by() {
    let strategy = AlwaysHashStrategy::new();

    // Valid: has GROUP BY columns
    let valid_metadata = QueryMetadata {
        group_by_columns: vec!["trader_id".to_string()],
        has_window: false,
        num_partitions: 8,
        num_cpu_slots: 8,
    };
    assert!(strategy.validate(&valid_metadata).is_ok());
}

/// Test strategy validation fails without GROUP BY columns
#[test]
fn test_strategy_validation_fails_without_group_by() {
    let strategy = AlwaysHashStrategy::new();

    // Invalid: no GROUP BY columns
    let invalid_metadata = QueryMetadata {
        group_by_columns: vec![],
        has_window: false,
        num_partitions: 8,
        num_cpu_slots: 8,
    };
    assert!(strategy.validate(&invalid_metadata).is_err());
}

/// Test deterministic routing: same GROUP BY key always routes to same partition
#[tokio::test]
async fn test_deterministic_routing_same_key() {
    let config = PartitionedJobConfig::default();
    let coordinator = AdaptiveJobProcessor::new(config)
        .with_group_by_columns(vec!["trader_id".to_string()])
        .with_strategy(Arc::new(AlwaysHashStrategy::new()));

    let (_managers, senders) = coordinator.initialize_partitions();

    // Create records with same GROUP BY key
    let mut record1 = HashMap::new();
    record1.insert(
        "trader_id".to_string(),
        FieldValue::String("trader_1".to_string()),
    );
    record1.insert("price".to_string(), FieldValue::String("100.0".to_string()));

    let mut record2 = HashMap::new();
    record2.insert(
        "trader_id".to_string(),
        FieldValue::String("trader_1".to_string()),
    );
    record2.insert("price".to_string(), FieldValue::String("101.0".to_string()));

    let records = vec![StreamRecord::new(record1), StreamRecord::new(record2)];

    // Process batch with strategy
    let result = coordinator
        .process_batch_with_strategy(records, &senders)
        .await;

    assert!(result.is_ok());
    assert_eq!(result.unwrap(), 2); // Both records processed

    // Verify messages are queued (would need to read channels to verify routing)
}

/// Test different GROUP BY keys route to same partition with high probability
#[tokio::test]
async fn test_multiple_keys_distribute_across_partitions() {
    let config = PartitionedJobConfig::default();
    let coordinator = AdaptiveJobProcessor::new(config)
        .with_group_by_columns(vec!["trader_id".to_string()])
        .with_strategy(Arc::new(AlwaysHashStrategy::new()));

    let (_managers, senders) = coordinator.initialize_partitions();

    // Create records with different GROUP BY keys
    let records: Vec<StreamRecord> = (0..100)
        .map(|i| {
            let mut record = HashMap::new();
            record.insert(
                "trader_id".to_string(),
                FieldValue::String(format!("trader_{}", i)),
            );
            record.insert("price".to_string(), FieldValue::String(format!("{}.0", i)));
            StreamRecord::new(record)
        })
        .collect();

    let result = coordinator
        .process_batch_with_strategy(records, &senders)
        .await;

    assert!(result.is_ok());
    assert_eq!(result.unwrap(), 100); // All records processed
}

/// Test routing with empty GROUP BY columns fails validation
#[tokio::test]
async fn test_routing_with_empty_group_by_fails() {
    let config = PartitionedJobConfig::default();
    let coordinator = AdaptiveJobProcessor::new(config)
        .with_group_by_columns(vec![])
        .with_strategy(Arc::new(AlwaysHashStrategy::new()));

    let (_managers, senders) = coordinator.initialize_partitions();

    let mut record = HashMap::new();
    record.insert(
        "trader_id".to_string(),
        FieldValue::String("trader_1".to_string()),
    );
    let records = vec![StreamRecord::new(record)];

    let result = coordinator
        .process_batch_with_strategy(records, &senders)
        .await;

    // Should fail due to validation error
    assert!(result.is_err());
}

/// Test routing with missing GROUP BY column in record fails gracefully
#[tokio::test]
async fn test_routing_with_missing_group_by_column_fails() {
    let config = PartitionedJobConfig::default();
    let coordinator = AdaptiveJobProcessor::new(config)
        .with_group_by_columns(vec!["trader_id".to_string()])
        .with_strategy(Arc::new(AlwaysHashStrategy::new()));

    let (_managers, senders) = coordinator.initialize_partitions();

    // Record missing required GROUP BY column
    let mut record = HashMap::new();
    record.insert("price".to_string(), FieldValue::String("100.0".to_string()));
    let records = vec![StreamRecord::new(record)];

    let result = coordinator
        .process_batch_with_strategy(records, &senders)
        .await;

    // Should fail due to missing column
    assert!(result.is_err());
}

/// Test strategy consistency: multiple keys produce different partitions
#[test]
fn test_strategy_distributes_keys_differently() {
    let _strategy = AlwaysHashStrategy::new();

    // Same key should always hash to same value
    let _routing_context = RoutingContext {
        source_partition: None,
        source_partition_key: None,
        group_by_columns: vec!["trader_id".to_string()],
        num_partitions: 8,
        num_cpu_slots: 8,
    };

    // Create records for testing
    let mut record1 = HashMap::new();
    record1.insert(
        "trader_id".to_string(),
        FieldValue::String("trader_1".to_string()),
    );

    let mut record2 = HashMap::new();
    record2.insert(
        "trader_id".to_string(),
        FieldValue::String("trader_2".to_string()),
    );

    // We would need async runtime to actually test route_record
    // For now, just verify the records can be created
    assert!(!record1.is_empty());
    assert!(!record2.is_empty());
}

/// Test coordinator builder pattern works correctly
#[test]
fn test_coordinator_builder_pattern() {
    let config = PartitionedJobConfig::default();

    // Build with fluent API
    let coordinator = AdaptiveJobProcessor::new(config)
        .with_group_by_columns(vec!["trader_id".to_string(), "symbol".to_string()])
        .with_strategy(Arc::new(AlwaysHashStrategy::new()));

    // Verify it's properly configured
    assert_eq!(coordinator.num_partitions(), num_cpus::get().max(1));
}

/// Test record batch processing maintains order within partition
#[tokio::test]
async fn test_batch_processing_maintains_consistency() {
    let config = PartitionedJobConfig::default();
    let coordinator = AdaptiveJobProcessor::new(config)
        .with_group_by_columns(vec!["trader_id".to_string()])
        .with_strategy(Arc::new(AlwaysHashStrategy::new()));

    let (_managers, senders) = coordinator.initialize_partitions();

    // Create batch of records with same GROUP BY key
    let records: Vec<StreamRecord> = (1..=10)
        .map(|i| {
            let mut record = HashMap::new();
            record.insert(
                "trader_id".to_string(),
                FieldValue::String("trader_1".to_string()),
            );
            record.insert("price".to_string(), FieldValue::String(format!("{}.0", i)));
            record.insert("sequence".to_string(), FieldValue::String(format!("{}", i)));
            StreamRecord::new(record)
        })
        .collect();

    let result = coordinator
        .process_batch_with_strategy(records, &senders)
        .await;

    assert!(result.is_ok());
    assert_eq!(result.unwrap(), 10); // All 10 records should be processed
}

/// Test strategy with compound GROUP BY (multiple columns)
#[tokio::test]
async fn test_compound_group_by_columns() {
    let config = PartitionedJobConfig::default();
    let coordinator = AdaptiveJobProcessor::new(config)
        .with_group_by_columns(vec![
            "trader_id".to_string(),
            "symbol".to_string(),
            "side".to_string(),
        ])
        .with_strategy(Arc::new(AlwaysHashStrategy::new()));

    let (_managers, senders) = coordinator.initialize_partitions();

    // Create record with compound GROUP BY key
    let mut record = HashMap::new();
    record.insert(
        "trader_id".to_string(),
        FieldValue::String("trader_1".to_string()),
    );
    record.insert("symbol".to_string(), FieldValue::String("APPL".to_string()));
    record.insert("side".to_string(), FieldValue::String("BUY".to_string()));
    record.insert("price".to_string(), FieldValue::String("150.0".to_string()));

    let records = vec![StreamRecord::new(record)];

    let result = coordinator
        .process_batch_with_strategy(records, &senders)
        .await;

    assert!(result.is_ok());
    assert_eq!(result.unwrap(), 1);
}

/// Test that throttling method also works with strategy
#[tokio::test]
async fn test_strategy_with_throttling() {
    let config = PartitionedJobConfig::default();
    let coordinator = AdaptiveJobProcessor::new(config)
        .with_group_by_columns(vec!["trader_id".to_string()])
        .with_strategy(Arc::new(AlwaysHashStrategy::new()));

    let (managers, senders) = coordinator.initialize_partitions();

    // Create test record
    let mut record = HashMap::new();
    record.insert(
        "trader_id".to_string(),
        FieldValue::String("trader_1".to_string()),
    );
    let records = vec![StreamRecord::new(record)];

    // Get metrics
    let metrics: Vec<Arc<_>> = managers.iter().map(|m| m.metrics()).collect();

    // Should process with throttling applied
    let result = coordinator
        .process_batch_with_strategy_and_throttling(records, &senders, &metrics)
        .await;

    assert!(result.is_ok());
}

/// Test SmartRepartitionStrategy with aligned source partition
#[tokio::test]
async fn test_smart_repartition_with_aligned_source() {
    let config = PartitionedJobConfig::default();
    let coordinator = AdaptiveJobProcessor::new(config)
        .with_group_by_columns(vec!["trader_id".to_string()])
        .with_strategy(Arc::new(SmartRepartitionStrategy::new()));

    let (_managers, senders) = coordinator.initialize_partitions();

    // Create record with __partition__ field (for aligned data detection)
    let mut record = HashMap::new();
    record.insert(
        "__partition__".to_string(),
        FieldValue::Integer(2), // Partition field for natural partitioning
    );
    record.insert(
        "trader_id".to_string(),
        FieldValue::String("trader_1".to_string()),
    );
    let records = vec![StreamRecord::new(record)];

    let result = coordinator
        .process_batch_with_strategy(records, &senders)
        .await;

    assert!(result.is_ok());
    assert_eq!(result.unwrap(), 1);
}

/// Test RoundRobinStrategy distributes records evenly
#[tokio::test]
async fn test_round_robin_even_distribution() {
    let config = PartitionedJobConfig::default();
    let coordinator = AdaptiveJobProcessor::new(config)
        .with_group_by_columns(vec![]) // RoundRobin works without GROUP BY
        .with_strategy(Arc::new(RoundRobinStrategy::new()));

    let (_managers, senders) = coordinator.initialize_partitions();

    // Create batch of records for round-robin
    let records: Vec<StreamRecord> = (0..16)
        .map(|i| {
            let mut record = HashMap::new();
            record.insert(
                "id".to_string(),
                FieldValue::String(format!("record_{}", i)),
            );
            StreamRecord::new(record)
        })
        .collect();

    let result = coordinator
        .process_batch_with_strategy(records, &senders)
        .await;

    assert!(result.is_ok());
    assert_eq!(result.unwrap(), 16);
}

/// Test StickyPartitionStrategy maintains record affinity
#[tokio::test]
async fn test_sticky_partition_maintains_affinity() {
    let config = PartitionedJobConfig::default();
    let coordinator = AdaptiveJobProcessor::new(config)
        .with_group_by_columns(vec!["trader_id".to_string()])
        .with_strategy(Arc::new(StickyPartitionStrategy::new()));

    let (_managers, senders) = coordinator.initialize_partitions();

    // Create records with same GROUP BY key (should maintain affinity via __partition__ field)
    let records: Vec<StreamRecord> = (1..=5)
        .map(|i| {
            let mut record = HashMap::new();
            record.insert(
                "__partition__".to_string(),
                FieldValue::Integer((i as i64) % 8), // Use partition field for affinity
            );
            record.insert(
                "trader_id".to_string(),
                FieldValue::String("trader_1".to_string()),
            );
            record.insert(
                "order_id".to_string(),
                FieldValue::String(format!("order_{}", i)),
            );
            StreamRecord::new(record)
        })
        .collect();

    let result = coordinator
        .process_batch_with_strategy(records, &senders)
        .await;

    assert!(result.is_ok());
    assert_eq!(result.unwrap(), 5);
}

/// Test all strategies can be created from factory
#[test]
fn test_factory_creates_all_strategies() {
    let test_configs = vec![
        StrategyConfig::AlwaysHash,
        StrategyConfig::SmartRepartition,
        StrategyConfig::RoundRobin,
        StrategyConfig::StickyPartition,
        StrategyConfig::FanIn,
    ];

    for config in test_configs {
        let strategy = StrategyFactory::create(config);
        assert!(strategy.is_ok(), "Failed to create strategy: {:?}", config);
        assert!(!strategy.unwrap().name().is_empty());
    }
}

/// Test factory string parsing for all strategies
#[test]
fn test_factory_string_parsing() {
    let test_cases = vec![
        ("always_hash", "AlwaysHash"),
        ("smart_repartition", "SmartRepartition"),
        ("round_robin", "RoundRobin"),
        ("sticky_partition", "StickyPartition"),
        ("fan_in", "FanIn"),
    ];

    for (input, expected_name) in test_cases {
        let strategy = StrategyFactory::create_from_str(input);
        assert!(strategy.is_ok(), "Failed to parse '{}'", input);
        assert_eq!(strategy.unwrap().name(), expected_name);
    }
}

/// Test all strategies handle missing required columns gracefully
#[tokio::test]
async fn test_all_strategies_fail_on_missing_column() {
    let strategies_should_fail: Vec<(&str, Arc<dyn PartitioningStrategy>)> = vec![
        ("AlwaysHash", Arc::new(AlwaysHashStrategy::new())),
        (
            "SmartRepartition",
            Arc::new(SmartRepartitionStrategy::new()),
        ),
    ];

    for (name, strategy) in strategies_should_fail {
        let config = PartitionedJobConfig::default();
        let coordinator = AdaptiveJobProcessor::new(config)
            .with_group_by_columns(vec!["trader_id".to_string()])
            .with_strategy(strategy);

        let (_managers, senders) = coordinator.initialize_partitions();

        // Record missing required GROUP BY column
        let mut record = HashMap::new();
        record.insert("price".to_string(), FieldValue::String("100.0".to_string()));
        let records = vec![StreamRecord::new(record)];

        let result = coordinator
            .process_batch_with_strategy(records, &senders)
            .await;

        assert!(
            result.is_err(),
            "Strategy {} should fail on missing GROUP BY column",
            name
        );
    }

    // StickyPartition uses record.partition field, not GROUP BY columns, so it should succeed
    let config = PartitionedJobConfig::default();
    let coordinator = AdaptiveJobProcessor::new(config)
        .with_group_by_columns(vec!["trader_id".to_string()])
        .with_strategy(Arc::new(StickyPartitionStrategy::new()));

    let (_managers, senders) = coordinator.initialize_partitions();

    // Record missing GROUP BY column but has partition info
    let mut record = HashMap::new();
    record.insert("price".to_string(), FieldValue::String("100.0".to_string()));
    record.insert("__partition__".to_string(), FieldValue::Integer(0));
    let records = vec![StreamRecord::new(record)];

    let result = coordinator
        .process_batch_with_strategy(records, &senders)
        .await;

    // StickyPartition should succeed because it uses __partition__ field, not GROUP BY columns
    assert!(
        result.is_ok(),
        "StickyPartition should succeed with __partition__ field even without GROUP BY column"
    );
}

/// Test strategy consistency across multiple batch operations
#[tokio::test]
async fn test_strategy_consistency_across_batches() {
    let config = PartitionedJobConfig::default();
    let coordinator = AdaptiveJobProcessor::new(config)
        .with_group_by_columns(vec!["trader_id".to_string()])
        .with_strategy(Arc::new(AlwaysHashStrategy::new()));

    let (_managers, senders) = coordinator.initialize_partitions();

    // Process multiple batches
    for batch_num in 0..3 {
        let records: Vec<StreamRecord> = (0..10)
            .map(|i| {
                let mut record = HashMap::new();
                record.insert(
                    "trader_id".to_string(),
                    FieldValue::String(format!("trader_{}", (batch_num * 10 + i) % 5)),
                );
                record.insert(
                    "batch".to_string(),
                    FieldValue::String(format!("{}", batch_num)),
                );
                StreamRecord::new(record)
            })
            .collect();

        let result = coordinator
            .process_batch_with_strategy(records, &senders)
            .await;

        assert!(result.is_ok());
        assert_eq!(result.unwrap(), 10);
    }
}

/// Test coordinator with SmartRepartitionStrategy builder
#[test]
fn test_coordinator_builder_with_smart_repartition() {
    let config = PartitionedJobConfig::default();
    let coordinator = AdaptiveJobProcessor::new(config)
        .with_group_by_columns(vec!["trader_id".to_string()])
        .with_strategy(Arc::new(SmartRepartitionStrategy::new()));

    assert_eq!(coordinator.num_partitions(), num_cpus::get().max(1));
}

/// Test coordinator with StickyPartitionStrategy builder
#[test]
fn test_coordinator_builder_with_sticky_partition() {
    let config = PartitionedJobConfig::default();
    let coordinator = AdaptiveJobProcessor::new(config)
        .with_group_by_columns(vec!["trader_id".to_string()])
        .with_strategy(Arc::new(StickyPartitionStrategy::new()));

    assert_eq!(coordinator.num_partitions(), num_cpus::get().max(1));
}

/// Test RoundRobinStrategy validation
#[test]
fn test_round_robin_validation_rejects_group_by() {
    let strategy = RoundRobinStrategy::new();

    let metadata_with_group_by = QueryMetadata {
        group_by_columns: vec!["trader_id".to_string()],
        has_window: false,
        num_partitions: 8,
        num_cpu_slots: 8,
    };

    // RoundRobin should reject GROUP BY (breaks aggregations)
    assert!(strategy.validate(&metadata_with_group_by).is_err());

    // But it should accept no GROUP BY (pass-through)
    let metadata_no_group_by = QueryMetadata {
        group_by_columns: vec![],
        has_window: false,
        num_partitions: 8,
        num_cpu_slots: 8,
    };

    assert!(strategy.validate(&metadata_no_group_by).is_ok());
}

/// Test FanInStrategy concentrates all records to single partition
#[tokio::test]
async fn test_fan_in_strategy_concentrates_records() {
    let config = PartitionedJobConfig::default();
    let coordinator = AdaptiveJobProcessor::new(config)
        .with_group_by_columns(vec![]) // FanIn doesn't require GROUP BY
        .with_strategy(Arc::new(FanInStrategy::new()));

    let (_managers, senders) = coordinator.initialize_partitions();

    // Create batch of records with different keys
    let records: Vec<StreamRecord> = (0..20)
        .map(|i| {
            let mut record = HashMap::new();
            record.insert(
                "id".to_string(),
                FieldValue::String(format!("record_{}", i)),
            );
            record.insert("value".to_string(), FieldValue::Integer(i as i64 * 100));
            StreamRecord::new(record)
        })
        .collect();

    let result = coordinator
        .process_batch_with_strategy(records, &senders)
        .await;

    // All 20 records should be processed and routed to same partition
    assert!(result.is_ok());
    assert_eq!(result.unwrap(), 20);
}
