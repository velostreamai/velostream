application: large_volume_demo
description: Test high volume data processing (10k records)
default_timeout_ms: 120000
default_records: 10000

queries:
  - name: enriched_events
    description: Verify transformation handles 10k records
    inputs:
      - source: events
        schema: events
        records: 10000
        time_simulation:
          start_time: "-5m"    # 5 minutes of events
          end_time: "now"
          sequential: true
    assertions:
      - type: record_count
        greater_than: 5000  # At least half should pass filter (value > 0)
      - type: schema_contains
        fields: [event_id, user_id, event_type, value, adjusted_value, region]
      - type: field_values
        field: value
        operator: greater_than
        value: 0
      - type: no_nulls
        fields: [event_id, user_id, value]
    timeout_ms: 90000

  - name: regional_stats
    description: Verify aggregation handles high volume correctly
    inputs:
      - source: events_2
        schema: events
        records: 10000
        time_simulation:
          start_time: "-5m"    # 5 minutes spans multiple 1-min tumbling windows
          end_time: "now"
          sequential: true
    assertions:
      - type: record_count
        greater_than: 0
      - type: schema_contains
        fields: [region, event_type, event_count, total_value, avg_value]
      - type: field_values
        field: event_count
        operator: greater_than
        value: 0
      - type: no_nulls
        fields: [region, event_type, event_count]
    timeout_ms: 90000
