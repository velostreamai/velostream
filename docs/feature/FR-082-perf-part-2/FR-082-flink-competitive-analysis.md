# FR-082: Flink Competitive Feature Analysis

**Date**: November 6, 2025
**Purpose**: Comprehensive feature gap analysis to ensure Velostream V2 is competitive with Apache Flink and other stream processing systems

---

## Executive Summary

This document analyzes Velostream Job Server V2 architecture against Apache Flink, identifying feature gaps and competitive advantages to ensure V2 is "better than Flink" as specified.

**Key Finding**: V2 blueprint has strong foundation but **CRITICAL GAPS** in SQL engine performance and several enterprise features.

---

## 1. Performance Foundation Analysis

### üö® CRITICAL GAP: SQL Engine GROUP BY Performance

**Problem**: V2 blueprint assumes 200K rec/sec GROUP BY throughput, but **actual baseline is 3.58K rec/sec** for **Pure GROUP BY with 5 aggregations** (Scenario 2 - Phase 4A findings).

**IMPORTANT SCENARIO DISTINCTION**: This gap applies to **Pure GROUP BY queries** (no WINDOW clause), which is the PRIMARY target for Phase 4B/4C optimization:

| Scenario | Description | Baseline Performance | Phase 4B/4C Applicable? |
|----------|-------------|---------------------|------------------------|
| **Pure GROUP BY** (Scenario 2) | `SELECT category, COUNT(*), SUM(...) GROUP BY category` | 3.58K rec/sec (5 aggs) | ‚úÖ **YES** (PRIMARY target) |
| **GROUP BY + Time Window** (Scenario 3) | `SELECT trader_id, COUNT(*) GROUP BY trader_id WINDOW TUMBLING(...)` | 127K rec/sec | ‚úÖ YES (GROUP BY portion) |
| **ROWS WINDOW** (Scenario 1) | `SELECT AVG(price) OVER (ROWS WINDOW BUFFER 100...)` | TBD (needs measurement) | ‚ùå NO (different state type) |

**Impact on V2**: Without fixing Pure GROUP BY (Scenario 2), V2 architecture cannot achieve stated targets:

| Component | V2 Target | Actual Baseline (Pure GROUP BY) | Gap |
|-----------|-----------|--------------------------------|-----|
| GROUP BY operations | 200K rec/sec | 3.58K rec/sec | **56x shortfall** |
| Multi-source scaling | 32M rec/sec (160 sources) | 574K rec/sec (160 √ó 3.58K) | **56x shortfall** |

**Root Causes** (from FR-082-PHASE4-BOTTLENECK_FINDINGS.md):
1. Vec&lt;String&gt; hash keys (~40% overhead)
2. Group state cloning per batch (~30% overhead)
3. String allocations in accumulators (~15% overhead)
4. generate_group_key allocations (~20% overhead)
5. Record cloning in accumulator (~10% overhead)

**Required Integration**: Phase 4B + 4C optimizations MUST be part of V2 core design:

```rust
// Phase 4B: Hash Table Optimization
struct GroupKey {
    hash: u64,                      // Pre-computed hash
    values: Arc<[FieldValue]>,      // Arc to avoid Vec allocation
}

// Use FxHashMap (2-3x faster than std HashMap)
FxHashMap<GroupKey, GroupAccumulator>

// Phase 4C: Arc-based State Sharing
pub struct GroupByState {
    groups: Arc<FxHashMap<GroupKey, GroupAccumulator>>,  // ‚Üê Arc wrapper
}

impl StreamExecutionEngine {
    pub fn get_group_state_ref(&self) -> Arc<FxHashMap<GroupKey, GroupAccumulator>> {
        Arc::clone(&self.group_states.groups)  // ‚Üê Cheap clone
    }

    pub fn merge_batch_state(&mut self, batch_state: FxHashMap<GroupKey, GroupAccumulator>) {
        let groups = Arc::make_mut(&mut self.group_states.groups);  // ‚Üê COW pattern
        for (key, batch_acc) in batch_state {
            groups.entry(key)
                .and_modify(|acc| acc.merge(&batch_acc))
                .or_insert(batch_acc);
        }
    }
}
```

**Expected Results with Phase 4B + 4C**:
- GROUP BY baseline: 3.58K ‚Üí 200K rec/sec ‚úÖ (matches V2 targets)
- Multi-source scaling: 32M rec/sec achievable ‚úÖ
- Job server overhead: Minimal (<10% with local merge pattern)

**Recommendation**: **INTEGRATE Phase 4B + 4C as V2 foundational requirement**, not optional optimization.

---

## 2. Core Stream Processing Features

### 2.1 State Management

| Feature | Flink | V2 Blueprint | Gap | Priority |
|---------|-------|--------------|-----|----------|
| **Keyed State** | ‚úÖ Per-key state with partitioning | ‚úÖ Via GROUP BY (with Phase 4B/4C) | None | - |
| **Operator State** | ‚úÖ Per-operator state | ‚ùå Not supported | Medium | P2 |
| **State Backends** | ‚úÖ Memory, RocksDB, custom | ‚ö†Ô∏è Memory only | Medium | P2 |
| **State TTL** | ‚úÖ Configurable expiration | ‚ùå Not mentioned | High | **P1** |
| **Queryable State** | ‚úÖ External queries to state | ‚ùå Not supported | Low | P3 |
| **State Schema Evolution** | ‚úÖ Versioned state | ‚ö†Ô∏è Basic versioning mentioned | Medium | P2 |
| **State Rescaling** | ‚úÖ Automatic on scale-out | ‚ùå Not mentioned | High | **P1** |

**Recommendations**:
1. **Add State TTL** (P1): Critical for long-running jobs with unbounded state growth
2. **Add State Rescaling** (P1): Required for dynamic partition rebalancing
3. **Add RocksDB backend** (P2): For state larger than memory

```rust
// Proposed State TTL API
pub struct StateTTLConfig {
    pub ttl: Duration,
    pub update_type: TTLUpdateType,  // OnCreate, OnReadAndWrite
    pub state_visibility: TTLStateVisibility,  // ReturnExpiredIfNotCleanedUp, NeverReturnExpired
    pub cleanup_strategy: TTLCleanupStrategy,  // OnRead, Incremental, RocksDBCompaction
}

impl StateManagerActor {
    pub fn configure_ttl(&mut self, config: StateTTLConfig) {
        self.ttl_config = Some(config);
    }

    async fn handle_group_update(&mut self, key: GroupKey, update: StateUpdate) {
        // Check TTL before processing
        if let Some(ttl) = &self.ttl_config {
            if self.is_expired(&key, ttl) {
                self.evict_state(&key).await;
                return;
            }
        }
        // ... normal update
    }
}
```

### 2.2 Time & Watermarks

| Feature | Flink | V2 Blueprint | Gap | Priority |
|---------|-------|--------------|-----|----------|
| **Event Time** | ‚úÖ Full support | ‚úÖ Via EventTimeExtractor | None | - |
| **Processing Time** | ‚úÖ System time | ‚ö†Ô∏è Not explicitly mentioned | Low | P3 |
| **Ingestion Time** | ‚úÖ Source arrival time | ‚ùå Not supported | Low | P3 |
| **Watermark Strategies** | ‚úÖ BoundedOutOfOrderness, Monotonous, Custom | ‚úÖ Periodic, Punctuated | None | - |
| **Watermark Alignment** | ‚úÖ Cross-partition alignment | ‚ùå Not mentioned | High | **P1** |
| **Idle Source Handling** | ‚úÖ Prevent watermark stalling | ‚ö†Ô∏è Basic timeout mentioned | Medium | P2 |
| **Late Data Side Output** | ‚úÖ Separate stream for late events | ‚ùå Not mentioned | Medium | P2 |

**Recommendations**:
1. **Add Watermark Alignment** (P1): Critical for multi-source correctness
2. **Add Late Data Side Output** (P2): Required for auditing and debugging
3. **Enhance Idle Source Handling** (P2): Current timeout mechanism is basic

```rust
// Proposed Watermark Alignment
pub struct WatermarkAlignmentConfig {
    pub max_drift: Duration,  // Maximum allowed drift between sources
    pub alignment_group: String,  // Group sources for alignment
}

impl WatermarkManager {
    pub async fn advance_watermark_aligned(
        &mut self,
        source_id: SourceId,
        watermark: Watermark,
        alignment: &WatermarkAlignmentConfig,
    ) -> Result<Option<Watermark>, WatermarkError> {
        // Track per-source watermarks
        self.source_watermarks.insert(source_id, watermark);

        // Check alignment constraint
        let min_watermark = self.source_watermarks.values().min().unwrap();
        let max_watermark = self.source_watermarks.values().max().unwrap();

        if max_watermark.timestamp - min_watermark.timestamp > alignment.max_drift {
            // Throttle fast sources, wait for slow sources
            return Ok(None);
        }

        // Advance global watermark to minimum
        self.global_watermark = min_watermark;
        Ok(Some(min_watermark))
    }
}
```

### 2.3 Windowing

**CRITICAL DISTINCTION**: Velostream supports three fundamentally different window types, each with distinct state management and optimization strategies:

1. **ROWS WINDOW** (Scenario 1): Memory-bounded sliding buffers with PARTITION BY (no GROUP BY)
2. **Time-based Windows WITHOUT GROUP BY** (Scenario 2a): TUMBLING/SLIDING/SESSION on raw stream
3. **Time-based Windows WITH GROUP BY** (Scenario 3): TUMBLING/SLIDING/SESSION + hash table aggregations

| Feature | Flink | V2 Blueprint | Gap | Priority | Notes |
|---------|-------|--------------|-----|----------|-------|
| **ROWS WINDOW (OVER clause)** | ‚úÖ Memory-bounded buffers | ‚úÖ Fully supported | None | - | State: `VecDeque` per partition, Phase 4B/4C N/A |
| **ROWS WINDOW + PARTITION BY** | ‚úÖ Per-partition buffers | ‚úÖ Fully supported | None | - | Optimization: Arc<StreamRecord>, circular buffers |
| **Tumbling Windows (Time)** | ‚úÖ Fixed-size time windows | ‚úÖ Time-based | None | - | State: Time metadata + optional GROUP BY hash |
| **Tumbling Windows (Count)** | ‚úÖ Fixed-size count windows | ‚ùå Not mentioned | Medium | P2 | Different trigger mechanism |
| **Sliding Windows (Time)** | ‚úÖ Overlapping time windows | ‚úÖ Mentioned | None | - | State: Multiple window instances |
| **Sliding Windows (Count)** | ‚úÖ Overlapping count windows | ‚ùå Not mentioned | Medium | P2 | Requires count-based triggers |
| **Session Windows** | ‚úÖ Gap-based dynamic windows | ‚úÖ Mentioned | None | - | State: Session gap metadata |
| **GROUP BY + Time Windows** | ‚úÖ Aggregations per window | ‚úÖ Fully supported | None | - | **CRITICAL**: Phase 4B/4C optimizes GROUP BY hash table |
| **Global Windows** | ‚úÖ All records in one window | ‚ùå Not mentioned | Low | P3 | Edge case, low priority |
| **Custom Window Assigners** | ‚úÖ Pluggable assigners | ‚ùå Not mentioned | Medium | P2 | Required for domain-specific windowing |
| **Window Triggers** | ‚úÖ EventTime, ProcessingTime, Count, Custom | ‚ö†Ô∏è Basic triggers | High | **P1** | Missing count and custom triggers |
| **Window Evictors** | ‚úÖ Remove elements before/after | ‚ùå Not mentioned | Low | P3 | Advanced feature, low priority |
| **Allowed Lateness** | ‚úÖ Late data within threshold | ‚ö†Ô∏è Basic late data handling | Medium | P2 | Needs refinement |
| **Side Outputs** | ‚úÖ Multiple output streams | ‚ùå Not mentioned | Medium | P2 | Critical for complex event processing |

**Performance Implications by Window Type**:

| Window Type | State Structure | Phase 4B/4C Applicable? | Baseline Performance | Optimization Strategy |
|-------------|----------------|------------------------|---------------------|----------------------|
| **ROWS WINDOW** | `HashMap<PartitionKey, VecDeque<StreamRecord>>` | ‚ùå No (different state type) | TBD (needs measurement) | Arc<StreamRecord>, circular buffers, efficient partition lookup |
| **Pure Time Window** | `Vec<WindowState>` (time metadata only) | ‚ùå No (no hash table) | High (simple time logic) | Efficient window tracking, watermark optimization |
| **GROUP BY + Time Window** | `Vec<WindowState>` + `HashMap<GroupKey, Accumulator>` | ‚úÖ **YES** (GROUP BY hash) | 127K rec/sec (baseline) | **Phase 4B/4C targets GROUP BY portion** |
| **Pure GROUP BY** | `HashMap<Vec<String>, Accumulator>` | ‚úÖ **YES** (PRIMARY target) | 3.58K rec/sec (5 aggs) | Phase 4B: FxHashMap + GroupKey (‚Üí15-20K), Phase 4C: Arc + interning (‚Üí200K) |

**Recommendations**:
1. **Add Advanced Triggers** (P1): Count, custom, and composite triggers for count-based windows
2. **Add Side Outputs** (P2): Critical for complex event processing patterns (late data, error handling)
3. **Add Custom Window Assigners** (P2): Required for domain-specific windowing logic
4. **Measure ROWS WINDOW baseline** (Phase 0): Establish performance baseline separate from GROUP BY scenarios
5. **Document window type selection** (Phase 1): Guide users to choose optimal window type for their use case

```rust
// Proposed Advanced Trigger API
pub enum WindowTrigger {
    EventTime,
    ProcessingTime,
    Count(usize),
    CountOrTime { count: usize, time: Duration },
    Custom(Box<dyn TriggerFunction>),
}

pub trait TriggerFunction: Send + Sync {
    fn on_element(&mut self, element: &StreamRecord, window: &Window) -> TriggerResult;
    fn on_event_time(&mut self, time: i64, window: &Window) -> TriggerResult;
    fn on_processing_time(&mut self, time: i64, window: &Window) -> TriggerResult;
}

pub enum TriggerResult {
    Continue,          // Keep accumulating
    Fire,              // Emit window result
    FireAndPurge,      // Emit and clear window
    Purge,             // Clear window without emitting
}

// Side Output API
pub struct SideOutput<T> {
    pub tag: OutputTag<T>,
    pub records: Vec<T>,
}

impl WindowProcessor {
    pub fn process_with_side_outputs(
        &mut self,
        window: &Window,
    ) -> (Vec<StreamRecord>, Vec<SideOutput<StreamRecord>>) {
        let mut main_output = Vec::new();
        let mut late_data = Vec::new();

        for record in &window.records {
            if record.event_time < window.end - self.allowed_lateness {
                late_data.push(record.clone());
            } else {
                main_output.push(record.clone());
            }
        }

        let side_outputs = vec![
            SideOutput {
                tag: OutputTag::new("late-data"),
                records: late_data,
            }
        ];

        (main_output, side_outputs)
    }
}
```

---

## 3. Fault Tolerance & Reliability

### 3.1 Checkpointing & Savepoints

| Feature | Flink | V2 Blueprint | Gap | Priority |
|---------|-------|--------------|-----|----------|
| **Periodic Checkpoints** | ‚úÖ Configurable interval | ‚úÖ Via two-phase commit | None | - |
| **Incremental Checkpoints** | ‚úÖ Only changed state (RocksDB) | ‚ùå Not mentioned | Medium | P2 |
| **Checkpoint Alignment** | ‚úÖ Barrier alignment across sources | ‚ùå Not mentioned | High | **P1** |
| **Unaligned Checkpoints** | ‚úÖ Low-latency checkpointing | ‚ùå Not mentioned | Medium | P2 |
| **Savepoints** | ‚úÖ Manual, versioned snapshots | ‚ùå Not mentioned | High | **P1** |
| **Checkpoint Storage** | ‚úÖ FS, S3, HDFS | ‚ö†Ô∏è Transaction log only | Medium | P2 |
| **Checkpoint Timeout** | ‚úÖ Configurable | ‚ö†Ô∏è Not explicitly mentioned | Low | P3 |

**Recommendations**:
1. **Add Checkpoint Alignment** (P1): Critical for exactly-once guarantees across multiple sources
2. **Add Savepoints** (P1): Required for version upgrades and A/B testing
3. **Add Incremental Checkpoints** (P2): Performance optimization for large state

```rust
// Proposed Checkpoint Alignment
pub struct CheckpointCoordinator {
    pending_barriers: HashMap<SourceId, CheckpointBarrier>,
    checkpoint_storage: Arc<dyn CheckpointStorage>,
}

pub struct CheckpointBarrier {
    pub checkpoint_id: u64,
    pub timestamp: i64,
}

impl CheckpointCoordinator {
    pub async fn handle_barrier(
        &mut self,
        source_id: SourceId,
        barrier: CheckpointBarrier,
    ) -> Result<Option<CheckpointBarrier>, CheckpointError> {
        // Track barriers from each source
        self.pending_barriers.insert(source_id, barrier.clone());

        // Check if all sources have sent this barrier
        if self.all_sources_received(barrier.checkpoint_id) {
            // Trigger checkpoint
            self.trigger_checkpoint(barrier.checkpoint_id).await?;
            self.pending_barriers.clear();
            return Ok(Some(barrier));
        }

        Ok(None)
    }

    pub async fn trigger_checkpoint(&mut self, checkpoint_id: u64) -> Result<(), CheckpointError> {
        // Snapshot all operator state
        let snapshot = self.snapshot_all_state().await?;

        // Persist to checkpoint storage
        self.checkpoint_storage.store(checkpoint_id, snapshot).await?;

        Ok(())
    }
}

// Savepoint API
pub struct SavepointMetadata {
    pub version: String,
    pub timestamp: i64,
    pub operator_states: HashMap<String, StateSnapshot>,
    pub watermarks: HashMap<SourceId, Watermark>,
}

impl CheckpointCoordinator {
    pub async fn trigger_savepoint(&mut self, path: &str) -> Result<SavepointMetadata, CheckpointError> {
        // Pause processing
        self.pause_all_sources().await?;

        // Take full snapshot with metadata
        let savepoint = SavepointMetadata {
            version: env!("CARGO_PKG_VERSION").to_string(),
            timestamp: Utc::now().timestamp_millis(),
            operator_states: self.snapshot_all_state().await?,
            watermarks: self.snapshot_watermarks().await?,
        };

        // Persist savepoint
        self.checkpoint_storage.store_savepoint(path, &savepoint).await?;

        // Resume processing
        self.resume_all_sources().await?;

        Ok(savepoint)
    }

    pub async fn restore_from_savepoint(&mut self, path: &str) -> Result<(), CheckpointError> {
        // Load savepoint
        let savepoint: SavepointMetadata = self.checkpoint_storage.load_savepoint(path).await?;

        // Verify version compatibility
        if !self.is_compatible_version(&savepoint.version) {
            return Err(CheckpointError::IncompatibleVersion);
        }

        // Restore all state
        self.restore_all_state(savepoint.operator_states).await?;
        self.restore_watermarks(savepoint.watermarks).await?;

        Ok(())
    }
}
```

### 3.2 Failure Recovery

| Feature | Flink | V2 Blueprint | Gap | Priority |
|---------|-------|--------------|-----|----------|
| **Automatic Recovery** | ‚úÖ From checkpoint | ‚úÖ Via transaction log | None | - |
| **Partial Recovery** | ‚úÖ Failed tasks only | ‚ùå Full job restart | High | **P1** |
| **Recovery Strategies** | ‚úÖ Restart-all, restart-failed, failover | ‚ö†Ô∏è Basic retry | Medium | P2 |
| **Task Failure Isolation** | ‚úÖ Continue processing on healthy tasks | ‚ùå Not mentioned | Medium | P2 |
| **Circuit Breaker** | ‚ö†Ô∏è Via external libs | ‚úÖ Built-in | **Advantage** | - |

**Recommendations**:
1. **Add Partial Recovery** (P1): Don't restart entire job on single source failure
2. **Add Recovery Strategies** (P2): Configurable recovery policies
3. **Keep Circuit Breaker Advantage**: Flink typically requires external libraries for this

```rust
// Proposed Partial Recovery
pub struct RecoveryStrategy {
    pub restart_policy: RestartPolicy,
    pub failure_isolation: FailureIsolation,
}

pub enum RestartPolicy {
    RestartAll,           // Restart entire job
    RestartFailed,        // Restart failed tasks only
    FailoverRegion,       // Restart connected region
}

pub enum FailureIsolation {
    Strict,               // Fail entire job on any task failure
    Lenient,              // Continue processing on healthy tasks
}

impl JobCoordinator {
    pub async fn handle_source_failure(
        &mut self,
        source_id: SourceId,
        error: SourceError,
    ) -> Result<(), RecoveryError> {
        match self.recovery_strategy.restart_policy {
            RestartPolicy::RestartAll => {
                // Current behavior: restart entire job
                self.restart_all_sources().await?;
            }
            RestartPolicy::RestartFailed => {
                // New: restart only failed source
                self.restart_source(source_id).await?;

                // Resync watermarks
                self.watermark_manager.reset_source(source_id).await?;
            }
            RestartPolicy::FailoverRegion => {
                // New: restart failed source + downstream operators
                let region = self.compute_failover_region(source_id);
                self.restart_region(region).await?;
            }
        }

        Ok(())
    }
}
```

---

## 4. Connectors & Integration

### 4.1 Source Connectors

| Connector | Flink | V2 Blueprint | Gap | Priority |
|-----------|-------|--------------|-----|----------|
| **Kafka** | ‚úÖ Full support | ‚úÖ Via DataReader | None | - |
| **Kafka Consumer Groups** | ‚úÖ Automatic partition assignment | ‚úÖ Mentioned for scaling | None | - |
| **File Sources** (CSV, JSON, Parquet) | ‚úÖ Batch & streaming | ‚ùå Not mentioned | Medium | P2 |
| **Database CDC** (Debezium) | ‚úÖ Change data capture | ‚ùå Not mentioned | Low | P3 |
| **Cloud Storage** (S3, GCS, Azure) | ‚úÖ Batch & streaming | ‚ùå Not mentioned | Low | P3 |
| **Message Queues** (RabbitMQ, Pulsar) | ‚úÖ Via connectors | ‚ùå Not mentioned | Low | P3 |
| **Custom Sources** | ‚úÖ Via SourceFunction | ‚úÖ Via DataReader trait | None | - |

### 4.2 Sink Connectors

| Connector | Flink | V2 Blueprint | Gap | Priority |
|-----------|-------|--------------|-----|----------|
| **Kafka** | ‚úÖ Exactly-once with transactions | ‚úÖ Via DataWriter | None | - |
| **File Sinks** (Parquet, ORC, Avro) | ‚úÖ Bucketing, rolling | ‚ùå Not mentioned | Medium | P2 |
| **JDBC** (PostgreSQL, MySQL) | ‚úÖ Exactly-once with XA | ‚ùå Not mentioned | Low | P3 |
| **Elasticsearch** | ‚úÖ Bulk writes | ‚ùå Not mentioned | Low | P3 |
| **Cassandra** | ‚úÖ Async writes | ‚ùå Not mentioned | Low | P3 |
| **Custom Sinks** | ‚úÖ Via SinkFunction | ‚úÖ Via DataWriter trait | None | - |

**Recommendation**: V2's DataReader/DataWriter traits provide excellent extensibility. Prioritize **File Sources/Sinks (P2)** for batch-streaming unification.

---

## 5. SQL & Table API Features

### 5.1 SQL Completeness

| Feature | Flink SQL | Velostream SQL | Gap | Priority |
|---------|-----------|----------------|-----|----------|
| **Window Aggregations** | ‚úÖ TUMBLE, HOP, SESSION | ‚úÖ TUMBLING, SLIDING, SESSION | None | - |
| **ROWS WINDOW (OVER)** | ‚úÖ Memory-bounded buffers | ‚úÖ Fully supported | None | - |
| **GROUP BY (Pure)** | ‚úÖ Optimized hash aggregation | ‚ö†Ô∏è **3.58K rec/sec** (5 aggs) | **CRITICAL** | **P0** |
| **GROUP BY + Time Windows** | ‚úÖ Windowed aggregations | ‚úÖ **127K rec/sec** baseline | None | - |
| **Joins** (Stream-Stream) | ‚úÖ With time bounds | ‚ö†Ô∏è Mentioned in V2 | Medium | P2 |
| **Joins** (Stream-Table) | ‚úÖ Lookup joins | ‚ùå Not mentioned | Medium | P2 |
| **Temporal Tables** | ‚úÖ Versioned lookups | ‚ùå Not mentioned | Low | P3 |
| **Top-N** | ‚úÖ Windowed top-N | ‚ùå Not mentioned | Medium | P2 |
| **Deduplication** | ‚úÖ DISTINCT on event time | ‚ùå Not mentioned | Medium | P2 |
| **MATCH_RECOGNIZE** | ‚úÖ Complex event processing | ‚ùå Not mentioned | Low | P3 |
| **User-Defined Functions** | ‚úÖ Scalar, Table, Aggregate | ‚ùå Not mentioned | High | **P1** |
| **Catalog Integration** | ‚úÖ Hive, JDBC | ‚ùå Not mentioned | Low | P3 |

**Critical Gap**: **Pure GROUP BY** performance (Scenario 2) is **56x below target** (3.58K vs 200K rec/sec). **MUST integrate Phase 4B + 4C** before any other SQL features.

**Note**: GROUP BY + Time Windows (Scenario 3) performs at 127K rec/sec baseline, which is 35x faster than pure GROUP BY. This inconsistency requires investigation (see FR-082-SCENARIO-CLARIFICATION.md).

**Recommendations**:
1. **Fix GROUP BY Performance** (P0): Phase 4B + 4C integration (FxHashMap, Arc state sharing)
2. **Add UDFs** (P1): Critical for custom business logic
3. **Add Top-N & Deduplication** (P2): Common streaming SQL patterns

```rust
// Proposed UDF API
pub trait ScalarFunction: Send + Sync {
    fn eval(&self, args: &[FieldValue]) -> Result<FieldValue, SqlError>;
}

pub trait TableFunction: Send + Sync {
    fn eval(&self, args: &[FieldValue]) -> Result<Vec<StreamRecord>, SqlError>;
}

pub trait AggregateFunction: Send + Sync {
    type Accumulator: Clone + Send + Sync;

    fn create_accumulator(&self) -> Self::Accumulator;
    fn accumulate(&self, acc: &mut Self::Accumulator, record: &StreamRecord) -> Result<(), SqlError>;
    fn get_result(&self, acc: &Self::Accumulator) -> Result<FieldValue, SqlError>;
    fn merge(&self, acc: &mut Self::Accumulator, other: &Self::Accumulator);
}

// Usage in SQL
impl StreamExecutionEngine {
    pub fn register_scalar_function(&mut self, name: &str, func: Arc<dyn ScalarFunction>) {
        self.scalar_functions.insert(name.to_string(), func);
    }

    pub fn register_aggregate_function(&mut self, name: &str, func: Arc<dyn AggregateFunction>) {
        self.aggregate_functions.insert(name.to_string(), func);
    }
}

// Example UDF
struct FinancialRound;

impl ScalarFunction for FinancialRound {
    fn eval(&self, args: &[FieldValue]) -> Result<FieldValue, SqlError> {
        if args.len() != 2 {
            return Err(SqlError::InvalidArguments);
        }

        let value = args[0].as_float()?;
        let decimals = args[1].as_integer()?;

        let multiplier = 10_f64.powi(decimals as i32);
        let rounded = (value * multiplier).round() / multiplier;

        Ok(FieldValue::Float(rounded))
    }
}

// SQL: SELECT financial_round(price, 2) FROM trades
```

---

## 6. Advanced Processing Features

### 6.1 Process Functions

| Feature | Flink | V2 Blueprint | Gap | Priority |
|---------|-------|--------------|-----|----------|
| **ProcessFunction** | ‚úÖ Low-level stream processing | ‚ùå Not mentioned | Medium | P2 |
| **KeyedProcessFunction** | ‚úÖ Per-key state + timers | ‚ùå Not mentioned | Medium | P2 |
| **CoProcessFunction** | ‚úÖ Two-stream processing | ‚ùå Not mentioned | Medium | P2 |
| **BroadcastProcessFunction** | ‚úÖ Broadcast state pattern | ‚ùå Not mentioned | Low | P3 |
| **Timers** (Event-time & Processing-time) | ‚úÖ Per-key timers | ‚ùå Not mentioned | Medium | P2 |

**Recommendation**: **Add ProcessFunction API (P2)** for advanced users who need low-level control beyond SQL.

### 6.2 Complex Event Processing

| Feature | Flink CEP | V2 Blueprint | Gap | Priority |
|---------|-----------|--------------|-----|----------|
| **Pattern Matching** | ‚úÖ Regex-like patterns | ‚ùå Not mentioned | Low | P3 |
| **Pattern Sequences** | ‚úÖ next(), followedBy(), notFollowedBy() | ‚ùå Not mentioned | Low | P3 |
| **Pattern Groups** | ‚úÖ Iteration (times, oneOrMore) | ‚ùå Not mentioned | Low | P3 |
| **Time Constraints** | ‚úÖ within(), until() | ‚ùå Not mentioned | Low | P3 |

**Recommendation**: **CEP is Low Priority (P3)** - can be built on top of ProcessFunction API.

---

## 7. Deployment & Operations

### 7.1 Deployment Models

| Feature | Flink | V2 Blueprint | Gap | Priority |
|---------|-------|--------------|-----|----------|
| **Standalone Cluster** | ‚úÖ Flink cluster | ‚úÖ Single binary | None | - |
| **YARN/Hadoop** | ‚úÖ Resource management | ‚ùå Not applicable (Rust) | None | - |
| **Kubernetes** | ‚úÖ Native operator | ‚ùå Not mentioned | High | **P1** |
| **Docker** | ‚úÖ Official images | ‚ö†Ô∏è Assumed but not mentioned | Low | P3 |
| **Cloud Services** (EMR, Dataproc) | ‚úÖ Managed Flink | ‚ùå Not applicable | None | - |

**Recommendation**: **Add Kubernetes Support (P1)** - critical for cloud-native deployments.

```yaml
# Proposed Kubernetes Deployment
apiVersion: velostream.io/v1alpha1
kind: StreamingJob
metadata:
  name: trading-analytics
spec:
  parallelism: 16
  sql: |
    SELECT
      trader_id,
      symbol,
      COUNT(*) as trade_count,
      SUM(price * quantity) as total_value
    FROM trades
    GROUP BY trader_id, symbol
    WINDOW TUMBLING (event_time, INTERVAL '1' MINUTE)

  sources:
    - name: trades
      type: kafka
      config:
        bootstrap.servers: kafka:9092
        topic: trades
        consumer.group: trading-analytics

  sinks:
    - name: results
      type: kafka
      config:
        bootstrap.servers: kafka:9092
        topic: trading-results

  resources:
    cpu: 4
    memory: 8Gi

  checkpoint:
    interval: 10s
    storage: s3://checkpoints/trading-analytics

  watermark:
    strategy: BoundedOutOfOrderness
    max_out_of_orderness: 5s
```

### 7.2 Resource Management

| Feature | Flink | V2 Blueprint | Gap | Priority |
|---------|-------|--------------|-----|----------|
| **Dynamic Parallelism** | ‚úÖ Adaptive scheduling | ‚ùå Not mentioned | Medium | P2 |
| **Task Slots** | ‚úÖ Shared resources | ‚ö†Ô∏è Via Kafka partitions | None | - |
| **Resource Profiles** | ‚úÖ Per-operator resources | ‚ùå Not mentioned | Low | P3 |
| **Backpressure Management** | ‚úÖ Network buffer tuning | ‚úÖ Channel-based | None | - |
| **CPU Pinning** | ‚ö†Ô∏è Manual configuration | ‚úÖ Built-in (V2) | **Advantage** | - |
| **NUMA Awareness** | ‚ö†Ô∏è Manual configuration | ‚úÖ Built-in (V2) | **Advantage** | - |

**Advantages**: V2's **NUMA awareness + CPU pinning** is superior to Flink's manual approach.

---

## 8. Observability & Monitoring

### 8.1 Metrics

| Feature | Flink | V2 Blueprint | Gap | Priority |
|---------|-------|--------------|-----|----------|
| **System Metrics** | ‚úÖ CPU, memory, network | ‚úÖ Via sysinfo | None | - |
| **Throughput Metrics** | ‚úÖ Records/sec per operator | ‚úÖ Via Prometheus | None | - |
| **Latency Metrics** | ‚úÖ p50, p95, p99 | ‚úÖ Via Prometheus | None | - |
| **Backpressure Metrics** | ‚úÖ Per-task backpressure | ‚ö†Ô∏è Not explicitly mentioned | Medium | P2 |
| **Checkpoint Metrics** | ‚úÖ Duration, size, alignment | ‚ö†Ô∏è Not explicitly mentioned | Medium | P2 |
| **Watermark Lag** | ‚úÖ Per-partition lag | ‚ö†Ô∏è Not explicitly mentioned | Medium | P2 |
| **Custom Metrics** | ‚úÖ User-defined metrics | ‚ùå Not mentioned | Low | P3 |

**Recommendation**: **Add Backpressure, Checkpoint, and Watermark Metrics (P2)** for production debugging.

### 8.2 Tracing & Debugging

| Feature | Flink | V2 Blueprint | Gap | Priority |
|---------|-------|--------------|-----|----------|
| **Distributed Tracing** | ‚ö†Ô∏è Via external tools | ‚úÖ OpenTelemetry/Jaeger | **Advantage** | - |
| **Flame Graphs** | ‚úÖ Via profiling tools | ‚ùå Not mentioned | Low | P3 |
| **Query Execution Plans** | ‚úÖ EXPLAIN PLAN | ‚ùå Not mentioned | Medium | P2 |
| **Visual Debugger** | ‚úÖ Flink Web UI | ‚ùå Not mentioned | Low | P3 |

**Advantage**: V2's **built-in distributed tracing** is superior to Flink's external-only approach.

---

## 9. Performance Optimizations

### 9.1 Execution Optimizations

| Feature | Flink | V2 Blueprint | Gap | Priority |
|---------|-------|--------------|-----|----------|
| **Operator Chaining** | ‚úÖ Fuse operators | ‚ùå Not mentioned | Medium | P2 |
| **Task Fusion** | ‚úÖ Combine tasks | ‚ùå Not mentioned | Medium | P2 |
| **Zero-Copy Serialization** | ‚úÖ Binary format | ‚ö†Ô∏è Mentioned but not detailed | Medium | P2 |
| **SIMD Aggregations** | ‚ùå Not mentioned | ‚úÖ Mentioned (V2) | **Advantage** | - |
| **Object Pooling** | ‚ö†Ô∏è Limited | ‚úÖ Built-in (V2) | **Advantage** | - |
| **Lock-Free Queues** | ‚ö†Ô∏è Mailbox system | ‚úÖ Built-in (V2) | **Advantage** | - |

**Advantages**: V2's **SIMD, object pooling, and lock-free queues** provide performance edge over Flink.

### 9.2 Query Optimization

| Feature | Flink SQL | V2 Blueprint | Gap | Priority |
|---------|-----------|--------------|-----|----------|
| **Predicate Pushdown** | ‚úÖ Filter early | ‚ùå Not mentioned | Medium | P2 |
| **Projection Pushdown** | ‚úÖ Select only needed fields | ‚ùå Not mentioned | Medium | P2 |
| **Join Reordering** | ‚úÖ Cost-based optimization | ‚ùå Not mentioned | Low | P3 |
| **Constant Folding** | ‚úÖ Compile-time evaluation | ‚ùå Not mentioned | Low | P3 |
| **Hash Join vs Nested Loop** | ‚úÖ Adaptive selection | ‚ùå Not mentioned | Low | P3 |

**Recommendation**: **Add Predicate/Projection Pushdown (P2)** for query performance.

---

## 10. Security & Compliance

### 10.1 Authentication & Authorization

| Feature | Flink | V2 Blueprint | Gap | Priority |
|---------|-------|--------------|-----|----------|
| **Kerberos** | ‚úÖ YARN/HDFS integration | ‚ùå Not applicable | None | - |
| **SSL/TLS** | ‚úÖ Internal communication | ‚ùå Not mentioned | Medium | P2 |
| **API Authentication** | ‚ö†Ô∏è External solutions | ‚ùå Not mentioned | Medium | P2 |
| **RBAC** | ‚ö†Ô∏è External solutions | ‚ùå Not mentioned | Low | P3 |

### 10.2 Data Security

| Feature | Flink | V2 Blueprint | Gap | Priority |
|---------|-------|--------------|-----|----------|
| **Encryption at Rest** | ‚úÖ Via state backends | ‚ùå Not mentioned | Medium | P2 |
| **Encryption in Transit** | ‚úÖ SSL/TLS | ‚ùå Not mentioned | Medium | P2 |
| **Data Masking** | ‚ö†Ô∏è Manual UDFs | ‚ùå Not mentioned | Low | P3 |
| **Audit Logging** | ‚ö†Ô∏è External solutions | ‚ùå Not mentioned | Low | P3 |

**Recommendation**: **Add SSL/TLS Support (P2)** for secure deployments.

---

## 11. Ecosystem & Compatibility

### 11.1 Language Support

| Feature | Flink | V2 Blueprint | Gap | Priority |
|---------|-------|--------------|-----|----------|
| **Java API** | ‚úÖ Primary | ‚ùå Not applicable (Rust) | None | - |
| **Scala API** | ‚úÖ Full support | ‚ùå Not applicable (Rust) | None | - |
| **Python API (PyFlink)** | ‚úÖ Table & DataStream | ‚ùå Not mentioned | Low | P3 |
| **SQL** | ‚úÖ Ansi SQL | ‚úÖ Streaming SQL | None | - |

### 11.2 Format Support

| Format | Flink | V2 Blueprint | Gap | Priority |
|--------|-------|--------------|-----|----------|
| **JSON** | ‚úÖ Full support | ‚úÖ Built-in | None | - |
| **Avro** | ‚úÖ Full support | ‚úÖ Built-in | None | - |
| **Protobuf** | ‚úÖ Full support | ‚úÖ Built-in | None | - |
| **Parquet** | ‚úÖ Full support | ‚ùå Not mentioned | Medium | P2 |
| **ORC** | ‚úÖ Full support | ‚ùå Not mentioned | Low | P3 |
| **CSV** | ‚úÖ Full support | ‚ùå Not mentioned | Low | P3 |

**Recommendation**: **Add Parquet Support (P2)** for analytics integration.

---

## 12. Competitive Advantages Summary

### V2 Advantages Over Flink

| Feature | Advantage | Impact |
|---------|-----------|--------|
| **Rust Performance** | Zero-cost abstractions, no GC pauses | 10-100x faster in certain workloads |
| **NUMA Awareness** | Built-in CPU pinning and cache locality | 2-3x improvement on large servers |
| **Lock-Free Architecture** | Actor-based state management | 5-10x lower latency |
| **SIMD Aggregations** | Vectorized operations | 2-4x aggregation speedup |
| **Object Pooling** | Built-in allocation reduction | 2-3x memory efficiency |
| **Distributed Tracing** | First-class OpenTelemetry integration | Superior observability |
| **Circuit Breaker** | Built-in resilience patterns | Better fault tolerance |
| **Sub-millisecond Latency** | Lock-free queues + object pooling | <1ms p95 latency target |

### Flink Advantages Over V2

| Feature | Advantage | Mitigation Priority |
|---------|-----------|-------------------|
| **Mature Ecosystem** | 10+ years, battle-tested | Accept (build over time) |
| **Rich Connectors** | 20+ built-in connectors | P2: Add file sources/sinks |
| **SQL Features** | Top-N, MATCH_RECOGNIZE, UDFs | P1: Add UDFs; P2: Top-N |
| **State Backends** | RocksDB for large state | P2: Add RocksDB backend |
| **Checkpoint Alignment** | Exactly-once across sources | **P1: Critical gap** |
| **Savepoints** | Version upgrades | **P1: Critical gap** |
| **Kubernetes Operator** | Cloud-native deployments | **P1: Critical gap** |
| **Community & Support** | Large community, commercial support | Accept (build over time) |

---

## 13. Critical Gaps Requiring Immediate Action (P0-P1)

### P0: Performance Foundation (Blocks V2 Targets)

**Issue**: GROUP BY baseline is 3.58K rec/sec, but V2 assumes 200K rec/sec (56x gap)

**Solution**: Integrate FR-082 Phase 4B + 4C into V2 core design:

```rust
// V2 StateManagerActor MUST include Phase 4B optimizations
pub struct StateManagerActor {
    // Phase 4B: FxHashMap with GroupKey (not Vec<String>)
    group_states: Arc<FxHashMap<GroupKey, GroupAccumulator>>,

    // Phase 4C: String interning pool
    string_interner: StringInterner,

    // Phase 4C: Group key cache
    key_cache: LruCache<u64, GroupKey>,
}

// Phase 4B: Optimized GroupKey
#[derive(Clone, PartialEq, Eq)]
pub struct GroupKey {
    hash: u64,                      // Pre-computed hash
    values: Arc<[FieldValue]>,      // Arc to avoid cloning
}

impl Hash for GroupKey {
    fn hash<H: Hasher>(&self, state: &mut H) {
        state.write_u64(self.hash);  // Use pre-computed hash
    }
}

// Phase 4C: Zero-allocation group key generation
impl StateManagerActor {
    fn generate_group_key_optimized(
        &mut self,
        expressions: &[Expr],
        record: &StreamRecord,
    ) -> Result<GroupKey, SqlError> {
        // Check cache first
        let record_hash = record.compute_hash();
        if let Some(cached) = self.key_cache.get(&record_hash) {
            return Ok(cached.clone());
        }

        // Extract values (reuse buffer from pool)
        let mut values = self.value_buffer_pool.acquire();
        values.clear();

        for expr in expressions {
            let value = ExpressionEvaluator::evaluate_expression_value(expr, record)?;
            values.push(value);
        }

        // Pre-compute hash
        let mut hasher = FxHasher::default();
        for value in &values {
            value.hash(&mut hasher);
        }
        let hash = hasher.finish();

        // Create key with Arc (cheap clone)
        let key = GroupKey {
            hash,
            values: Arc::from(values.as_slice()),
        };

        // Cache for future lookups
        self.key_cache.insert(record_hash, key.clone());

        Ok(key)
    }
}
```

**Implementation**: 1 week (Phase 4B) + 1 week (Phase 4C) = 2 weeks

**Expected Result**: 3.58K ‚Üí 200K rec/sec (56x improvement) ‚úÖ Meets V2 targets

---

### P1: State Management Gaps

#### 1. State TTL

**Why Critical**: Unbounded state growth breaks long-running jobs

**Implementation**: 3 days

```rust
pub struct StateTTLConfig {
    pub ttl: Duration,
    pub update_type: TTLUpdateType,
    pub cleanup_strategy: TTLCleanupStrategy,
}

impl StateManagerActor {
    async fn handle_group_update(&mut self, key: GroupKey, update: StateUpdate) {
        // Check TTL
        if self.is_expired(&key) {
            self.evict_state(&key).await;
            return;
        }
        // ... normal update
    }
}
```

#### 2. State Rescaling

**Why Critical**: Cannot rebalance state when scaling out

**Implementation**: 5 days

```rust
impl StateManagerActor {
    pub async fn redistribute_state(&mut self, new_partition_count: usize) -> Result<(), StateError> {
        // Snapshot current state
        let snapshot = self.snapshot_all_state().await?;

        // Redistribute by key hash
        let redistributed = snapshot.repartition(new_partition_count);

        // Send to new partition owners
        for (partition_id, state) in redistributed {
            self.send_state_transfer(partition_id, state).await?;
        }

        Ok(())
    }
}
```

---

### P1: Fault Tolerance Gaps

#### 1. Checkpoint Alignment

**Why Critical**: Exactly-once semantics require barrier alignment across sources

**Implementation**: 1 week

```rust
pub struct CheckpointCoordinator {
    pending_barriers: HashMap<SourceId, CheckpointBarrier>,
}

impl CheckpointCoordinator {
    pub async fn handle_barrier(
        &mut self,
        source_id: SourceId,
        barrier: CheckpointBarrier,
    ) -> Result<Option<CheckpointBarrier>, CheckpointError> {
        self.pending_barriers.insert(source_id, barrier.clone());

        // Check if all sources ready
        if self.all_sources_received(barrier.checkpoint_id) {
            self.trigger_checkpoint(barrier.checkpoint_id).await?;
            return Ok(Some(barrier));
        }

        Ok(None)
    }
}
```

#### 2. Savepoints

**Why Critical**: Cannot perform zero-downtime upgrades

**Implementation**: 1 week

```rust
impl CheckpointCoordinator {
    pub async fn trigger_savepoint(&mut self, path: &str) -> Result<SavepointMetadata, CheckpointError> {
        self.pause_all_sources().await?;

        let savepoint = SavepointMetadata {
            version: env!("CARGO_PKG_VERSION").to_string(),
            timestamp: Utc::now().timestamp_millis(),
            operator_states: self.snapshot_all_state().await?,
        };

        self.checkpoint_storage.store_savepoint(path, &savepoint).await?;
        self.resume_all_sources().await?;

        Ok(savepoint)
    }
}
```

---

### P1: Deployment Gaps

#### 1. Kubernetes Support

**Why Critical**: Cloud-native deployment standard

**Implementation**: 2 weeks

```yaml
apiVersion: velostream.io/v1alpha1
kind: StreamingJob
metadata:
  name: trading-analytics
spec:
  parallelism: 16
  sql: |
    SELECT trader_id, COUNT(*) as count
    FROM trades
    GROUP BY trader_id
    WINDOW TUMBLING (event_time, INTERVAL '1' MINUTE)

  checkpoint:
    interval: 10s
    storage: s3://checkpoints/
```

---

### P1: SQL Feature Gaps

#### 1. User-Defined Functions

**Why Critical**: Custom business logic required for production use

**Implementation**: 1 week

```rust
pub trait ScalarFunction: Send + Sync {
    fn eval(&self, args: &[FieldValue]) -> Result<FieldValue, SqlError>;
}

impl StreamExecutionEngine {
    pub fn register_scalar_function(&mut self, name: &str, func: Arc<dyn ScalarFunction>) {
        self.scalar_functions.insert(name.to_string(), func);
    }
}
```

---

### P1: Watermark Gaps

#### 1. Watermark Alignment

**Why Critical**: Multi-source correctness requires aligned watermarks

**Implementation**: 5 days

```rust
impl WatermarkManager {
    pub async fn advance_watermark_aligned(
        &mut self,
        source_id: SourceId,
        watermark: Watermark,
        max_drift: Duration,
    ) -> Result<Option<Watermark>, WatermarkError> {
        self.source_watermarks.insert(source_id, watermark);

        let min = self.source_watermarks.values().min().unwrap();
        let max = self.source_watermarks.values().max().unwrap();

        // Throttle if drift too large
        if max.timestamp - min.timestamp > max_drift.as_millis() as i64 {
            return Ok(None);
        }

        self.global_watermark = min;
        Ok(Some(min))
    }
}
```

---

## 14. Implementation Roadmap

### Phase 0: Performance Foundation (2 weeks) - **CRITICAL**

**Goal**: Fix GROUP BY performance to enable V2 targets

1. Week 1: Phase 4B - FxHashMap + GroupKey optimization
   - Replace `HashMap<Vec<String>, _>` with `FxHashMap<GroupKey, _>`
   - Pre-computed hashing
   - **Expected**: 3.58K ‚Üí 15-20K rec/sec

2. Week 2: Phase 4C - Arc-based state sharing
   - `Arc<FxHashMap>` for group states
   - String interning
   - Group key caching
   - **Expected**: 15-20K ‚Üí 200K rec/sec ‚úÖ Meets targets

**Deliverable**: GROUP BY at 200K rec/sec baseline

---

### Phase 1: Core V2 Architecture (4 weeks)

**Prerequisites**: Phase 0 completed

1. Week 3-4: Actor-based state management
   - StateManagerActor with FxHashMap
   - Message passing for state updates
   - Local merge pattern in ProcessingWorkers

2. Week 5-6: Source/Sink pipeline refactoring
   - Async stream pipelines
   - Automatic backpressure
   - Batch coordination

**Deliverable**: V2 architecture with 200K rec/sec single-source, 8x improvement

---

### Phase 2: P1 Feature Gaps (6 weeks)

1. Week 7: State TTL + State Rescaling
2. Week 8-9: Checkpoint Alignment + Savepoints
3. Week 10-11: Kubernetes Support
4. Week 12: User-Defined Functions + Watermark Alignment

**Deliverable**: Production-ready V2 with critical enterprise features

---

### Phase 3: P2 Feature Enhancements (8 weeks)

1. Weeks 13-14: Advanced windowing (triggers, side outputs)
2. Weeks 15-16: File sources/sinks (Parquet, CSV)
3. Weeks 17-18: Query optimization (predicate/projection pushdown)
4. Weeks 19-20: Incremental checkpoints + RocksDB backend

**Deliverable**: Feature-complete V2 competitive with Flink

---

### Phase 4: P3 Features & Polish (ongoing)

- Python API (PyVelo)
- CEP library
- Additional connectors
- Visual debugger
- Commercial support

---

## 15. Success Metrics

### Performance Targets (After Phase 0)

| Metric | Current (Phase 4A) | Phase 0 Target | V2 Target (Phase 1) | Notes |
|--------|-------------------|----------------|---------------------|-------|
| **Pure GROUP BY (Scenario 2)** | 3.58K rec/sec (5 aggs) | 200K rec/sec | 200K rec/sec | PRIMARY Phase 4B/4C target |
| **GROUP BY + Time Window (Scenario 3)** | 127K rec/sec | TBD | 400K rec/sec | Phase 4B/4C improves GROUP BY portion |
| **ROWS WINDOW (Scenario 1)** | TBD (needs measurement) | TBD | TBD | Different optimization path |
| **Multi-source scaling** | N/A | 200K rec/sec | 1.6M rec/sec (8 sources) | Based on Pure GROUP BY perf |
| **Horizontal scaling** | N/A | N/A | 32M rec/sec (160 sources) | V2 actor architecture |
| **Latency (p95)** | N/A | N/A | <1ms | Message-passing overhead |

### Feature Completeness Targets

| Category | Phase 0 | Phase 1 | Phase 2 | Phase 3 |
|----------|---------|---------|---------|---------|
| **State Management** | N/A | Basic | +TTL, +Rescaling | +RocksDB |
| **Fault Tolerance** | N/A | Basic | +Alignment, +Savepoints | +Incremental |
| **SQL Features** | +Phase4B/4C | Basic | +UDFs, +Top-N | +CEP |
| **Deployment** | N/A | Standalone | +Kubernetes | +Cloud |
| **Observability** | N/A | Basic | +Enhanced Metrics | +Visual Debugger |

---

## 16. Final Recommendation

### Must-Have Before V2 Launch (P0-P1)

‚úÖ **Phase 0: GROUP BY Performance** (2 weeks)
- Phase 4B: FxHashMap + GroupKey
- Phase 4C: Arc state sharing
- **Non-negotiable**: Without this, V2 targets are impossible

‚úÖ **Phase 1: Core V2 Architecture** (4 weeks)
- Actor-based state management
- Message-passing architecture
- Build on Phase 0 foundation

‚úÖ **Phase 2: P1 Gaps** (6 weeks)
- State TTL + Rescaling
- Checkpoint Alignment + Savepoints
- Kubernetes Support
- UDFs + Watermark Alignment

**Total Timeline**: 12 weeks to production-ready "better than Flink" V2

### Competitive Positioning

**Velostream V2 will be "better than Flink" in**:
1. **Performance**: 10-100x faster (Rust, NUMA, SIMD, lock-free)
2. **Latency**: <1ms p95 (object pooling, lock-free queues)
3. **Observability**: Built-in distributed tracing
4. **Resource Efficiency**: No GC pauses, lower memory footprint
5. **Simplicity**: Single binary, no JVM tuning

**Flink remains better in**:
1. **Ecosystem maturity**: 10+ years, battle-tested
2. **Connector breadth**: 20+ built-in connectors (mitigated by DataReader/DataWriter traits)
3. **Community size**: Large community, commercial support
4. **Enterprise features**: Some advanced features like CEP, MATCH_RECOGNIZE (roadmap for V2)

**Conclusion**: After implementing Phase 0-2 (12 weeks), V2 will be **competitive with Flink for 80% of use cases** and **superior for performance-critical workloads** (trading, real-time analytics, IoT).

---

**Generated**: November 6, 2025
**Last Updated**: November 6, 2025
**Status**: Ready for Phase 0 implementation
