# V2 Architecture Comparison: Single Actor vs Hash-Partitioned Pipeline

## Executive Summary

**Problem Identified**: Original V2 blueprint used single StateManagerActor â†’ serialization bottleneck

**Solution**: Hash-partitioned pipeline with N state managers (one per CPU core)

**Result**: Linear scaling instead of fixed throughput ceiling

---

## Side-by-Side Comparison

### Architecture Diagram

**Single Actor (Original V2)**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Worker 1â”‚â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ Worker 2â”‚â”€â”€â”¼â”€â”€â–º StateManagerActor â”€â”€â–º Output
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      (200K rec/sec)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    SERIALIZATION POINT
â”‚ Worker Nâ”‚â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Hash-Partitioned (New V2)**:
```
              Hash Router
                  â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚           â”‚           â”‚
      â–¼           â–¼           â–¼
  State Mgr   State Mgr   State Mgr
  Partition 0 Partition 1 Partition N
  [200K r/s]  [200K r/s]  [200K r/s]
      â”‚           â”‚           â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
              N Ã— 200K rec/sec
           LINEAR SCALING
```

---

## Key Differences

| Aspect | Single Actor | Hash-Partitioned | Impact |
|--------|--------------|------------------|--------|
| **Throughput** | Fixed at 200K rec/sec | N Ã— 200K rec/sec | 7.5x on 8 cores |
| **Latency (p95)** | 2-5ms | <1ms | 5x faster |
| **CPU Utilization** | 1 core saturated | N cores balanced | NÃ— efficiency |
| **Scaling** | Does not scale | Linear scaling | Critical for production |
| **Contention** | All workers â†’ 1 actor | Zero contention | No lock/queue delays |
| **Cache Locality** | Poor (shared state) | Excellent (pinned cores) | 2-3x speedup |
| **Backpressure** | Global only | Per-partition | Fine-grained control |
| **Fault Isolation** | None | Per-partition | Better reliability |

---

## Throughput Scaling Model

### Single Actor (Original V2)

```
Cores:  1    2    4    8    16   32
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Actor: 200K 200K 200K 200K 200K 200K  â† FLAT LINE (bottleneck)
```

**Problem**: Adding more workers doesn't increase throughput - they all queue up at the single actor

### Hash-Partitioned (New V2)

```
Cores:  1    2    4     8     16    32
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Pipes: 200K 380K 750K 1.5M  2.9M  5.4M  â† LINEAR GROWTH
```

**Benefit**: Each additional core adds ~200K rec/sec throughput

---

## Code Structure Changes

### Single Actor (Original)

```rust
// V2 Original: Single state manager
struct StateManagerActor {
    receiver: mpsc::UnboundedReceiver<StateMessage>,
    states: HashMap<String, QueryState>,  // ALL queries, ALL state
}

// Workers send to single actor
worker.state_tx.send(StateMessage::MergeBatchState {
    batch_state: local_state,
    response: tx,
}).await;

// BOTTLENECK: All state merges serialize through one actor
impl StateManagerActor {
    async fn run(mut self) {
        while let Some(msg) = self.receiver.recv().await {
            // Process ONE message at a time
            self.handle_message(msg);  // â† Serialization point
        }
    }
}
```

### Hash-Partitioned (New)

```rust
// V2 New: N partition managers
struct PartitionStateManager {
    partition_id: usize,
    receiver: mpsc::UnboundedReceiver<PartitionMessage>,
    query_states: FxHashMap<String, PartitionQueryState>,  // Only THIS partition's state
}

// Router determines partition based on GROUP BY key
let partition_id = hash(group_key) % num_partitions;
partition_senders[partition_id].send(msg).await;

// NO BOTTLENECK: N managers process in parallel
// Each manager runs on its own CPU core (pinned)
for partition_id in 0..num_partitions {
    let manager = PartitionStateManager::new(partition_id, rx);
    tokio::spawn(async move {
        manager.run().await;  // â† Runs in parallel with others
    });
}
```

---

## Performance Numbers

### Current State (V1)

- **Throughput**: 23K rec/sec
- **Overhead**: 97% (33x slower than pure SQL)
- **Bottleneck**: Arc<Mutex> lock contention

### Single Actor V2 (Original Blueprint)

- **Throughput**: 200K rec/sec (fixed)
- **Improvement over V1**: 8.7x
- **Limitation**: Cannot scale beyond 200K regardless of core count

### Hash-Partitioned V2 (New Blueprint)

| Cores | Throughput | Improvement over V1 | Efficiency |
|-------|-----------|---------------------|------------|
| 1     | 200K      | 8.7x                | 100%       |
| 2     | 380K      | 16.5x               | 95%        |
| 4     | 750K      | 32.6x               | 94%        |
| 8     | 1.5M      | 65.2x               | 93%        |
| 16    | 2.9M      | 126x                | 90%        |
| 32    | 5.4M      | 235x                | 85%        |

**Why 8 cores is optimal**: 93% efficiency with massive throughput gain (65x over V1)

---

## Why Partitioning Works for GROUP BY

### Natural Partitioning Property

**GROUP BY queries** have a critical property: **each group is independent**

```sql
SELECT trader_id, symbol, COUNT(*), AVG(price)
FROM trades
GROUP BY trader_id, symbol
```

**Key insight**:
- Group (trader=T1, symbol=SYM1) aggregations are completely independent from (trader=T2, symbol=SYM2)
- No cross-group dependencies
- Perfect for hash partitioning

### Hash Assignment Example

```
Records:                              Partitions:
â”€â”€â”€â”€â”€â”€â”€â”€â”€                             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

(T1, SYM1, 100.5) â”€â”€â”€hashâ”€â†’ 5 â”€â”€â†’  Partition 5: {
(T1, SYM1, 101.2) â”€â”€â”€hashâ”€â†’ 5 â”€â”€â†’    (T1,SYM1): count=2, avg=100.85
(T2, SYM2, 50.0)  â”€â”€â”€hashâ”€â†’ 3 â”€â”€â†’  }
(T3, SYM1, 99.8)  â”€â”€â”€hashâ”€â†’ 7 â”€â”€â†’  Partition 3: {
(T1, SYM1, 102.0) â”€â”€â”€hashâ”€â†’ 5 â”€â”€â†’    (T2,SYM2): count=1, avg=50.0
                                     }
                                   Partition 7: {
                                     (T3,SYM1): count=1, avg=99.8
                                   }
```

**Result**: Each partition aggregates independently, in parallel, with zero coordination

---

## Migration Path

### Option 1: Feature Flag

```rust
let processor = if config.use_hash_partitioned {
    PartitionedJobCoordinator::new(config)
} else {
    SimpleJobProcessor::new(config)  // V1
};
```

### Option 2: Configuration-Based

```yaml
job_server:
  architecture: partitioned  # or "single_actor" or "v1"
  num_partitions: 8
  enable_core_affinity: true
```

### Option 3: Automatic Selection

```rust
// Auto-select based on query and system resources
let processor = if query.has_group_by() && num_cpus::get() >= 4 {
    PartitionedJobCoordinator::new(config)
} else {
    SimpleJobProcessor::new(config)
};
```

---

## When to Use Each Architecture

### Single Actor (Original V2)

**Use when**:
- âœ… Low throughput requirements (<100K rec/sec)
- âœ… Single core / low core count machines
- âœ… Queries without GROUP BY (global state)
- âœ… Strong total ordering required

**Avoid when**:
- âŒ High throughput needed (>500K rec/sec)
- âŒ Multi-core machines available (8+ cores)
- âŒ GROUP BY queries (natural partitioning)
- âŒ Ultra-low-latency requirements (p95 <1ms)

### Hash-Partitioned (New V2)

**Use when**:
- âœ… **GROUP BY queries** (the common case!)
- âœ… **High throughput** (>500K rec/sec)
- âœ… **Multi-core machines** (4+ cores)
- âœ… **Ultra-low-latency** (p95 <1ms)
- âœ… **Horizontal scaling** needed

**Velostream's primary use case**: All checkmarks above â†’ **Hash-Partitioned is the right choice**

---

## Implementation Roadmap

### Phase 0: SQL Engine (Same for Both)

**Weeks 1-2**: Phase 4B + 4C optimizations
- âœ… Target: 200K rec/sec GROUP BY baseline
- Required for BOTH architectures

### Single Actor V2 (Original)

**Weeks 3-8**:
- Week 3: StateManagerActor implementation
- Week 4: ProcessingWorker pool
- Week 5: Source/sink pipelines
- Week 6-8: Observability, recovery, TTL

**Result**: 200K rec/sec (fixed)

### Hash-Partitioned V2 (New)

**Weeks 3-8**:
- Week 3: HashRouter + PartitionStateManager
- Week 4: PartitionedJobCoordinator
- Week 5: Backpressure + Prometheus metrics
- Week 6: System fields + watermarks
- Week 7-8: ROWS WINDOW, state TTL, recovery

**Result**: 1.5M rec/sec on 8 cores (linear scaling)

**Same effort, 7.5x better throughput!**

---

## Recommendation

### For Velostream V2: Use Hash-Partitioned Architecture

**Rationale**:

1. **Primary workload is GROUP BY queries** (financial analytics)
   - Natural fit for hash partitioning
   - No coordination overhead

2. **Target deployment: Multi-core machines** (8+ cores)
   - Hash-partitioned scales linearly
   - Single actor wastes 7 cores

3. **Performance requirements: >1M rec/sec**
   - Single actor caps at 200K
   - Hash-partitioned achieves 1.5M on 8 cores

4. **Latency requirements: p95 <1ms**
   - Single actor: 2-5ms (queueing delay)
   - Hash-partitioned: <1ms (no contention)

5. **Implementation effort: Identical**
   - Same 8-week timeline
   - Similar code complexity
   - Hash-partitioned is actually simpler (no cross-partition state merging)

**Conclusion**: Hash-partitioned architecture provides 7.5x better throughput for the same implementation cost.

---

## Next Steps

1. âœ… **Review new blueprint**: `FR-082-job-server-v2-PARTITIONED-PIPELINE.md`
2. ğŸ”§ **Complete Phase 0**: Phase 4B + 4C (200K rec/sec baseline)
3. ğŸ”§ **Implement Phase 1**: HashRouter + PartitionStateManager (Week 3)
4. ğŸ”§ **Validate scaling**: Measure 1, 2, 4, 8 partition performance
5. ğŸ”§ **Production deployment**: Rollout with feature flag

**Timeline**: 8 weeks total (2 weeks Phase 0 + 6 weeks implementation)

**Expected Outcome**: 65x improvement over V1 on 8-core machines (23K â†’ 1.5M rec/sec)

---

**Document Status**: Architecture Decision Record
**Decision**: Proceed with Hash-Partitioned Pipeline Architecture
**Date**: November 6, 2025
**Approved By**: Pending review
