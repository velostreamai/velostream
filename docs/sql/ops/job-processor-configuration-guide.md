# SQL Job Processor Configuration Guide

## Overview

When you submit a SQL job without explicit processor configuration, Velostream automatically selects *
*SimpleJobProcessor** with sensible defaults. This guide documents the three processor types, their defaults, use cases,
and actual performance characteristics.

> **üìö Related Documentation:**
> - For **high-level decision guidance** on when to use each processor,
    see [Job Processor Selection Guide](../../developer/job-processor-selection-guide.md)
> - That guide covers use cases, performance comparisons, and migration strategies
> - This guide focuses on **configuration details, defaults, and SQL syntax**

---

## Part 1: Default SQL Job Configuration (Unconfigured SQL)

When you provide SQL without any processor configuration:

```sql
CREATE
STREAM market_analysis AS
SELECT symbol, AVG(price)
FROM market_data
GROUP BY symbol;
```

Velostream applies `JobProcessingConfig::default()` which selects:

### Default Processor: SimpleJobProcessor

**Automatic Configuration:**

| Property                   | Default Value      | Purpose                                      |
|----------------------------|--------------------|----------------------------------------------|
| **processor_type**         | SimpleJobProcessor | Single-threaded, best-effort delivery        |
| **use_transactions**       | false              | No ACID guarantees, simpler semantics        |
| **failure_strategy**       | LogAndContinue     | Log errors and continue processing           |
| **max_batch_size**         | 100 records        | Balance between throughput and latency       |
| **batch_timeout**          | 1000ms (1s)        | Wait up to 1 second for batch completion     |
| **max_retries**            | 10 attempts        | Retry failed batches up to 10 times          |
| **retry_backoff**          | 5000ms (5s)        | Wait 5 seconds between retry attempts        |
| **enable_dlq**             | true               | Dead Letter Queue enabled for error recovery |
| **empty_batch_count**      | 1000               | Exit after 1000 empty batches from source    |
| **wait_on_empty_batch_ms** | 1000ms (1s)        | Wait 1 second between empty batch checks     |
| **log_progress**           | true               | Log progress every 10 batches                |
| **progress_interval**      | 10 batches         | Report metrics every 10 batches              |

---

## Part 2: SimpleJobProcessor Configuration

### When to Use Simple Mode

- **High-throughput scenarios** where acceptable data loss is tolerable
- **Best-effort delivery** systems (no ACID requirements)
- **Throughput-optimized** pipelines
- **Non-critical data** processing (logs, analytics, metrics)
- **Stateless transformations** that don't require atomicity

### Performance Characteristics

**Benchmark Results (records/second):**

```
Query Type                  Throughput    Notes
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Pure SELECT                 656,347       Baseline for simple queries
ROWS WINDOW                 959,923       ‚≠ê BEST - Perfect for windowing
GROUP BY                    318,968       Good for aggregations
TUMBLING + GROUP BY         365,489       Reasonable for complex aggregations
TUMBLING + EMIT CHANGES     8,741         Low throughput (emission overhead)
```

**Comparison to Raw SQL:**

- **SQLSync baseline:** 792,927 rec/sec (Pure SELECT)
- **SimpleJp achieves:** 82.7% of raw SQL performance
- **ROWS WINDOW:** 96% faster than SQLSync (959K vs 420K async)

### Default Configuration

```rust
// src/velostream/server/processors/common.rs:255-271
JobProcessingConfig {
max_batch_size: 100,
batch_timeout: Duration::from_millis(1000),
use_transactions: false,
failure_strategy: FailureStrategy::LogAndContinue,
max_retries: 10,
retry_backoff: Duration::from_millis(5000),
log_progress: true,
progress_interval: 10,
empty_batch_count: 1000,
wait_on_empty_batch_ms: 1000,
enable_dlq: true,  // ‚Üê Enables Dead Letter Queue
}
```

### Failure Handling with LogAndContinue Strategy

When a record fails to process:

1. **Error is logged** - Full error details recorded to application logs
2. **Record skipped** - Processing continues with next record
3. **DLQ entry created** - Failed record stored in Dead Letter Queue for analysis
4. **Stats updated** - `records_failed` counter incremented
5. **Batch commits** - Even with failures, batch is committed if not using FailBatch strategy

**Example:**

```log
[WARN] Job 'market_analysis': Source 'kafka_input' had 3 failures (continuing)
[DEBUG] DLQ Entry: Record 45 - Invalid JSON format in price field
[DEBUG] DLQ Entry: Record 67 - Null value in mandatory symbol field
[DEBUG] DLQ Entry: Record 89 - Price exceeds maximum allowed value
```

### Dead Letter Queue (DLQ) Configuration

**DLQ is enabled by default for SimpleJobProcessor:**

- **Purpose:** Captures failed records for debugging and recovery
- **Storage:** In-memory queue or persistent sink (configurable)
- **Access:** Available via observability metrics and error tracking APIs
- **Use case:** Post-mortem analysis of processing failures

**Disable DLQ if:**

- Error overhead is a concern in ultra-high-throughput scenarios
- You don't need error recovery or debugging
- Processing failures are intentionally ignored

```rust
// Disable DLQ explicitly
SimpleJobProcessor::new(JobProcessingConfig {
enable_dlq: false,  // Disable for maximum throughput
..Default::default ()
})
```

### Performance Profile Presets

SimpleJobProcessor provides three pre-configured profiles optimized for different use cases:

#### 1. Throughput-Optimized Profile (Default)

**Use case:** Maximum records/second, acceptable latency

```rust
// src/velostream/server/processors/simple.rs:996-1007
SimpleJobProcessor::new(JobProcessingConfig {
use_transactions: false,
failure_strategy: FailureStrategy::LogAndContinue,
max_batch_size: 1000,          // Large batches ‚Üí high throughput
batch_timeout: Duration::from_millis(100),  // Short timeout
max_retries: 1,                // Minimal retries for speed
retry_backoff: Duration::from_millis(100),
progress_interval: 100,
..Default::default ()
})
```

**Performance:** ~650K-960K rec/sec (depending on query complexity)

**Trade-offs:**

- ‚úÖ Highest throughput
- ‚ùå Higher latency per record
- ‚ùå Fewer retries (potential data loss on transient failures)

#### 2. Conservative Profile

**Use case:** Reliability over speed, smaller batches to isolate failures

```rust
// src/velostream/server/processors/simple.rs:1010-1021
SimpleJobProcessor::new(JobProcessingConfig {
use_transactions: false,
failure_strategy: FailureStrategy::FailBatch,  // Conservative strategy
max_batch_size: 100,           // Smaller batches for isolation
batch_timeout: Duration::from_millis(1000),    // Longer timeout
max_retries: 3,                // More retries
retry_backoff: Duration::from_millis(1000),
progress_interval: 10,         // More frequent logging
..Default::default ()
})
```

**Performance:** ~300K-600K rec/sec (30-40% slower but more reliable)

**Trade-offs:**

- ‚úÖ Smaller batches isolate failures
- ‚úÖ More frequent retries
- ‚úÖ Frequent progress logging helps debugging
- ‚ùå Lower throughput
- ‚ùå More logging overhead

#### 3. Low-Latency Profile

**Use case:** Ultra-responsive systems (p95 <1ms), willing to trade throughput

```rust
// src/velostream/server/processors/simple.rs:1024-1036
SimpleJobProcessor::new(JobProcessingConfig {
use_transactions: false,
failure_strategy: FailureStrategy::LogAndContinue,
max_batch_size: 10,            // Tiny batches for ultra-low latency
batch_timeout: Duration::from_millis(10),     // Very short timeout
max_retries: 0,                // No retries (reduce latency)
retry_backoff: Duration::from_millis(1),
progress_interval: 1000,       // Infrequent logging
log_progress: false,           // Disable progress logging
..Default::default ()
})
```

**Performance:** ~100K-200K rec/sec (lower throughput)

**Trade-offs:**

- ‚úÖ Ultra-low latency (p95 <1ms)
- ‚úÖ Minimal batch processing overhead
- ‚ùå Lowest throughput
- ‚ùå No retries (transient failures fail immediately)
- ‚ùå No logging overhead

### SQL Configuration

> ‚ö†Ô∏è **Note:** SQL-based configuration via WITH clauses is planned for a future release. Currently, processor
> configuration must be done programmatically via code or environment variables, not through SQL annotations.

SQL configuration examples (planned feature - not yet implemented):

```sql
-- PLANNED: Basic simple mode (explicit)
-- CREATE STREAM analytics AS
-- SELECT * FROM events
-- WITH ('mode' = 'simple', 'failure_strategy' = 'LogAndContinue');

-- Large batches for throughput
CREATE
STREAM high_throughput AS
SELECT *
FROM events WITH ('mode' = 'simple', 'max_batch_size' = '1000', 'batch_timeout' = '100ms');

-- Small batches for low latency
CREATE
STREAM responsive AS
SELECT *
FROM events WITH ('mode' = 'simple', 'max_batch_size' = '10', 'batch_timeout' = '10ms');

-- Annotation syntax
-- @processor_mode: simple
CREATE
STREAM default_simple AS
SELECT *
FROM events;
```

---

## Part 3: TransactionalJobProcessor Configuration

### How to Enable Transactional Mode

> ‚ö†Ô∏è **Note:** SQL-based configuration via WITH clauses and annotations is planned for a future release. Currently,
> processor configuration must be done programmatically via code.

Configuration methods (current and planned):

**Currently Supported: Programmatic Configuration**

- Use code/environment variables to set `use_transactions: true`
- See application documentation for your language/framework

**Planned: SQL-based Configuration**

Planned Method 1: WITH Clause (mode property)

```sql
-- PLANNED: Not yet implemented
-- CREATE STREAM financial_trades AS
-- SELECT symbol, SUM(quantity) as total_volume
-- FROM trades
-- WITH ('mode' = 'transactional', 'max_retries' = '5');
```

Planned Method 2: WITH Clause (use_transactions property)

```sql
-- PLANNED: Not yet implemented
-- CREATE STREAM atomic_updates AS
-- SELECT * FROM transactions
-- WITH ('use_transactions' = 'true', 'failure_strategy' = 'FailBatch');
```

Planned Method 3: SQL Annotation

```sql
-- PLANNED: Not yet implemented
-- @processor_mode: transactional
-- CREATE STREAM payment_processing AS
-- SELECT * FROM payment_events;
```

### When to Use Transactional Mode

- **Financial transactions** - Money transfers, trading, accounting
- **ACID guarantees required** - All-or-nothing batch semantics
- **Data consistency critical** - No partial batch commits
- **Idempotent operations** - Safe to retry without side effects
- **Regulatory compliance** - Audit trail and atomicity required

### Performance Characteristics

**Benchmark Results (records/second):**

```
Query Type                  Throughput    vs SimpleJp    Notes
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Pure SELECT                 739,244       +12.6%        ‚úÖ FASTER
ROWS WINDOW                 961,531       +0.2%         ‚≠ê FASTEST OVERALL
GROUP BY                    323,154       +1.3%
TUMBLING + GROUP BY         370,722       +1.4%
TUMBLING + EMIT CHANGES     8,822         +0.9%
```

**Surprising Result:** TransactionalJobProcessor is **faster or equal** to SimpleJobProcessor in all scenarios!

**Explanation:**

- Transaction overhead is minimal (Kafka/data source handles atomicity)
- FailBatch strategy eliminates partial commits (cleaner batching)
- Comparable CPU utilization to SimpleJobProcessor

### Default Configuration

```rust
// src/velostream/server/processors/transactional.rs:1591-1601
TransactionalJobProcessor::new(JobProcessingConfig {
use_transactions: true,
failure_strategy: FailureStrategy::FailBatch,  // Atomic batch semantics
enable_dlq: false,  // ‚Üê DLQ disabled (batch is rolled back)
max_retries: 10,
retry_backoff: Duration::from_millis(5000),
..Default::default ()
})
```

### Failure Handling with FailBatch Strategy

When any record in a batch fails:

1. **Entire batch is rolled back** - No records from this batch are committed
2. **Error is logged** - Full error details recorded
3. **DLQ is NOT used** - Batch rollback makes individual record tracking unnecessary
4. **Retry triggered** - Batch is retried after backoff period (with RetryWithBackoff strategy)
5. **At-least-once semantics** - Records may be reprocessed on retry, but all succeed or all fail

**Example:**

```log
[ERROR] Job 'payment_processing': Batch 42 - Record 15 failed validation
[WARN] Job 'payment_processing': Aborting batch transaction (all records rolled back)
[INFO] Job 'payment_processing': Applying retry backoff of 5s before retrying batch
[DEBUG] Job 'payment_processing': Retrying batch 42 with all 100 records
```

**Transaction Ordering (Critical for At-Least-Once):**

1. **Sink transaction commits first** - Write output records to sink (Kafka, etc.)
2. **Then source transaction commits** - Advance read position in source

**Why this order?**

- If sink succeeds but source fails, data will be reprocessed (at-least-once)
- If source succeeds but sink fails, data is lost (unacceptable)
- This asymmetric ordering prioritizes delivery over deduplication

### DLQ Disabled by Default

**Why DLQ is disabled for TransactionalJobProcessor:**

- **FailBatch rolls back everything** - Failed records are not persisted to sink
- **No individual record errors** - Entire batch fails atomically
- **DLQ would be empty** - No failed records to store
- **Focus on batch-level recovery** - Retry mechanism handles all failure scenarios

**When to enable DLQ for TransactionalJobProcessor:**

```rust
TransactionalJobProcessor::new(JobProcessingConfig {
use_transactions: true,
enable_dlq: true,  // Explicitly enable for debugging
..Default::default ()
})
```

### Transactional Processor Variants

#### 1. Default Transactional Profile

```rust
// src/velostream/server/processors/transactional.rs:1591-1601
TransactionalJobProcessor::new(JobProcessingConfig {
use_transactions: true,
failure_strategy: FailureStrategy::FailBatch,  // Strict atomicity
..Default::default ()
})
```

**Characteristics:**

- ‚úÖ Strict ACID compliance
- ‚úÖ Atomic batch semantics
- ‚úÖ At-least-once delivery
- ‚ùå Higher latency on failures (full batch retry)

#### 2. Best-Effort Transactional Profile

```rust
// src/velostream/server/processors/transactional.rs:1603-1614
TransactionalJobProcessor::new(JobProcessingConfig {
use_transactions: true,
failure_strategy: FailureStrategy::LogAndContinue,  // More lenient
max_retries: 1,
..Default::default ()
})
```

**Characteristics:**

- ‚úÖ ACID compliance with partial failures allowed
- ‚úÖ Lower latency (fewer retries)
- ‚úÖ At-least-once delivery
- ‚ùå Some records may fail silently

### SQL Configuration

```sql
-- Default transactional (FailBatch strategy)
CREATE
STREAM atomic_trades AS
SELECT *
FROM trades WITH ('mode' = 'transactional');

-- With explicit failure strategy
CREATE
STREAM trade_processing AS
SELECT *
FROM trades WITH (
    'use_transactions' = 'true',
    'failure_strategy' = 'FailBatch',
    'max_retries' = '5',
    'retry_backoff' = '2000ms'
);

-- Best-effort variant
CREATE
STREAM lenient_transactions AS
SELECT *
FROM trades WITH (
    'use_transactions' = 'true',
    'failure_strategy' = 'LogAndContinue',
    'max_retries' = '1'
);
```

---

## Part 4: AdaptiveJobProcessor Configuration

### How to Enable Adaptive Mode

```sql
-- Default (CPU count partitions)
CREATE
STREAM parallel_processing AS
SELECT *
FROM events WITH ('processor' = 'adaptive');

-- Explicit partition count
CREATE
STREAM 8way_parallel AS
SELECT *
FROM events WITH ('processor' = 'adaptive', 'num_partitions' = '8');

-- With core affinity pinning
CREATE
STREAM affinity_optimized AS
SELECT *
FROM events WITH ('processor' = 'adaptive:8:affinity');

-- Annotation syntax
-- @processor_mode: adaptive
CREATE
STREAM default_adaptive AS
SELECT *
FROM events;
```

### When to Use Adaptive Mode (Once Scaling Is Fixed)

- **Multi-core systems** with 4+ CPU cores
- **High-throughput workloads** requiring 100K+ rec/sec
- **Adaptive partitioning** for varying data distribution
- **Large datasets** processed in parallel
- **Linear scaling requirement** (8 cores = 8x throughput)

### Performance Characteristics

‚ö†Ô∏è **CRITICAL PERFORMANCE ISSUE:**

```
Query Type                  @1 core    @4 cores   Expected@4c   Status
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Pure SELECT                 24,408     24,551     ~98K          ‚ùå NOT SCALING
ROWS WINDOW                 24,563     24,372     ~98K          ‚ùå NOT SCALING
GROUP BY                    24,420     24,331     ~98K          ‚ùå NOT SCALING
TUMBLING + GROUP BY         24,513     24,283     ~98K          ‚ùå NOT SCALING
TUMBLING + EMIT CHANGES     24,357     24,249     ~98K          ‚ùå NOT SCALING
```

**Current State:**

- **Actual throughput:** ~24K rec/sec (independent of core count)
- **Expected throughput:** ~190K rec/sec on 8 cores
- **Scaling efficiency:** ~1.0x (no scaling benefit currently)

**Root Cause:** Partitioning strategy selection not optimized for query types

**Expected Partitioner by Query:**

```
Pure SELECT:        always_hash
ROWS WINDOW:        sticky_partition
GROUP BY:           always_hash
TUMBLING+GROUP BY:  sticky_partition
TUMBLING+EMIT:      sticky_partition
```

### Default Configuration

```rust
// src/velostream/server/v2/coordinator.rs:90-109
PartitionedJobConfig {
num_partitions: None,               // Defaults to CPU count
processing_mode: ProcessingMode::Individual,  // Ultra-low latency
partition_buffer_size: 1000,
enable_core_affinity: false,
backpressure_config: BackpressureConfig::default (),
partitioning_strategy: None,        // Defaults to AlwaysHashStrategy
auto_select_from_query: None,       // Auto-selection disabled by default
sticky_partition_id: None,
annotation_partition_count: None,
empty_batch_count: 3,               // Faster EOF detection than Simple
wait_on_empty_batch_ms: 100,        // Shorter wait (100ms vs 1000ms)
max_retries: 3,
retry_backoff: Duration::from_millis(1000),
failure_strategy: FailureStrategy::LogAndContinue,
}
```

### Configuration Options

#### Partition Count Configuration

```sql
-- Auto-detect partition count (uses CPU count)
WITH ('processor' = 'adaptive')

-- Explicit partition count
    WITH ('processor' = 'adaptive', 'num_partitions' = '8')

-- Annotation
-- @partition_count: 8
```

**Guidance:**

- **1-2 cores:** Use SimpleJp/TransJp (Adaptive overhead exceeds benefit)
- **4-8 cores:** Set `num_partitions` to CPU count (good scaling)
- **16+ cores:** Consider multiple Adaptive instances or pinning strategies

#### Partitioning Strategy Selection

Four strategies available:

| Strategy                    | Best For                      | Characteristics                   |
|-----------------------------|-------------------------------|-----------------------------------|
| **AlwaysHashStrategy**      | Pure SELECT, GROUP BY         | Distributes evenly, no ordering   |
| **StickyPartitionStrategy** | ROWS WINDOW, tumbling windows | Keeps related records together    |
| **SmartRepartition**        | Mixed queries                 | Auto-selects based on cardinality |
| **RoundRobin**              | Uniform distribution          | Simple round-robin assignment     |

**Configuration:**

```sql
-- Explicit strategy
WITH ('processor' = 'adaptive', 'partitioning_strategy' = 'sticky_partition')

-- Query-aware auto-selection (when implemented)
    WITH ('processor' = 'adaptive', 'auto_select_strategy' = 'true')
```

#### Core Affinity Pinning (Linux only)

```sql
-- Pin partitions to CPU cores for cache locality
WITH ('processor' = 'adaptive:8:affinity')
```

**Benefits:**

- Reduced cache misses
- Better NUMA locality
- ~5-10% throughput improvement on large systems

**Requirements:**

- Linux kernel support
- Must have `enable_core_affinity: true`

### Test-Optimized Mode

For testing with finite datasets, use immediate EOF detection:

```rust
// src/velostream/server/processors/job_processor_factory.rs:101-132
JobProcessorFactory::create_adaptive_test_optimized(Some(4))
```

**Configuration:**

```rust
PartitionedJobConfig {
num_partitions: Some(4),
empty_batch_count: 0,         // Immediate EOF detection
wait_on_empty_batch_ms: 0,    // No wait
..Default::default ()
}
```

**Benefits:**

- Eliminates 200-300ms EOF polling overhead
- Suitable for test datasets with deterministic end
- Not suitable for production (would exit prematurely on slow sources)

### Recommendations

**Until AdaptiveJp scaling is fixed:**

1. **Use TransactionalJobProcessor for production:**
   ```sql
   WITH ('mode' = 'transactional')
   ```
    - ‚úÖ 739K rec/sec (best overall performance)
    - ‚úÖ ACID guarantees
    - ‚úÖ Proven scaling characteristics

2. **Use SimpleJobProcessor for high-throughput:**
   ```sql
   WITH ('mode' = 'simple', 'max_batch_size' = '1000')
   ```
    - ‚úÖ 656K rec/sec (82% of raw SQL)
    - ‚úÖ Minimal overhead
    - ‚úÖ LogAndContinue strategy for resilience

3. **Avoid AdaptiveJobProcessor for now:**
   ```sql
   WITH ('processor' = 'adaptive')  -- NOT RECOMMENDED
   ```
    - ‚ùå 24K rec/sec (only 40% of Simple/Trans)
    - ‚ùå No linear scaling benefit
    - ‚è≥ Under investigation/optimization

---

## Part 5: Performance Comparison & Selection Guide

### Performance Summary

**Best to Worst by Query Type:**

```
ROWS WINDOW (BEST overall throughput):
1. TransJp      961,531 rec/sec  ‚≠ê WINNER
2. SimpleJp     959,923 rec/sec  (0.2% slower)
3. AdaptiveJp   24,372 rec/sec   (97% slower)

Pure SELECT:
1. TransJp      739,244 rec/sec  ‚≠ê WINNER
2. SimpleJp     656,347 rec/sec  (11.2% slower)
3. AdaptiveJp   24,551 rec/sec   (96.7% slower)

GROUP BY:
1. TransJp      323,154 rec/sec  ‚≠ê WINNER
2. SimpleJp     318,968 rec/sec  (1.3% slower)
3. AdaptiveJp   24,331 rec/sec   (92.5% slower)

TUMBLING + GROUP BY:
1. TransJp      370,722 rec/sec  ‚≠ê WINNER
2. SimpleJp     365,489 rec/sec  (1.4% slower)
3. AdaptiveJp   24,283 rec/sec   (93.4% slower)

TUMBLING + EMIT CHANGES:
1. TransJp      8,822 rec/sec    ‚≠ê WINNER
2. SimpleJp     8,741 rec/sec    (0.9% slower)
3. AdaptiveJp   24,249 rec/sec   (175% faster!)
```

### Baseline Comparison

Comparison to raw SQL execution:

```
                    SQLSync Baseline    SimpleJp        TransJp         Achievement
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Pure SELECT         792,927             656,347         739,244         93.2% of baseline
ROWS WINDOW         420,899 (async)     959,923         961,531         228% of async!
GROUP BY            290,291             318,968         323,154         111% of baseline
```

**Key insight:** SimpleJp and TransJp provide **job processing capabilities** while maintaining **near-SQL performance
** (82-100% of raw SQL)

### Selection Decision Tree

```
Start: Do you need atomicity?
‚îÇ
‚îú‚îÄ‚Üí YES
‚îÇ  ‚îî‚îÄ‚Üí Financial/payment processing?
‚îÇ      ‚îî‚îÄ‚Üí YES: Use TransactionalJobProcessor ‚úÖ
‚îÇ              (961K rec/sec + ACID)
‚îÇ      ‚îî‚îÄ‚Üí NO: Use SimpleJobProcessor
‚îÇ             (958K rec/sec, simpler)
‚îÇ
‚îî‚îÄ‚Üí NO
   ‚îî‚îÄ‚Üí Need best-effort?
       ‚îî‚îÄ‚Üí YES: Use SimpleJobProcessor ‚úÖ
              (656K rec/sec, LogAndContinue)
       ‚îî‚îÄ‚Üí NO: Use TransactionalJobProcessor anyway
              (739K rec/sec, faster + safer)
```

### By Query Type

| Query                   | Recommended | Throughput | Reason                         |
|-------------------------|-------------|------------|--------------------------------|
| **Pure SELECT**         | TransJp     | 739K       | Best overall, only 1% overhead |
| **ROWS WINDOW**         | TransJp     | 961K       | ‚≠ê Fastest overall processor    |
| **GROUP BY**            | TransJp     | 323K       | 1% faster than Simple          |
| **TUMBLING + GROUP BY** | TransJp     | 370K       | Slight edge over Simple        |
| **TUMBLING + EMIT**     | TransJp     | 8.8K       | Minimal difference             |

**Universal recommendation:** **Use TransactionalJobProcessor** - it's faster in all cases while providing ACID
guarantees.

### By Performance Profile

| Need                   | Processor | Profile              | Throughput       |
|------------------------|-----------|----------------------|------------------|
| **Maximum throughput** | SimpleJp  | Throughput-optimized | 960K rec/sec     |
| **ACID + throughput**  | TransJp   | Default              | 961K rec/sec     |
| **Reliability**        | SimpleJp  | Conservative         | 300-600K rec/sec |
| **Ultra-low latency**  | SimpleJp  | Low-latency          | 100-200K rec/sec |

---

## Part 6: Configuration Reference

### SQL WITH Clause Properties

```sql
-- Processor selection
WITH ('mode' = 'simple') -- Simple mode
    WITH ('mode' = 'transactional')       -- Transactional mode
WITH ('processor' = 'adaptive') -- Adaptive mode

-- Batch configuration
WITH ('max_batch_size' = '500') -- Records per batch
WITH ('batch_timeout' = '500ms') -- Time to wait for batch

-- Retry configuration
WITH ('max_retries' = '5') -- Number of retries
WITH ('retry_backoff' = '3000ms') -- Wait between retries

-- Failure handling
WITH ('failure_strategy' = 'LogAndContinue')
WITH ('failure_strategy' = 'FailBatch')
WITH ('failure_strategy' = 'RetryWithBackoff')

-- Adaptive-specific
WITH ('processor' = 'adaptive')
WITH ('processor' = 'adaptive', 'num_partitions' = '8')
WITH ('partitioning_strategy' = 'sticky_partition')

-- DLQ control
WITH ('enable_dlq' = 'true') -- Enable Dead Letter Queue
WITH ('enable_dlq' = 'false') -- Disable for max throughput
```

### Annotation Syntax

```sql
-- @processor_mode: simple
-- @processor_mode: transactional
-- @processor_mode: adaptive

-- @partition_count: 8
-- @sticky_partition_id: 2
-- @partitioning_strategy: sticky_partition
```

### JobProcessorFactory API

```rust
// Simple mode
JobProcessorFactory::create_simple()
JobProcessorFactory::create_conservative_simple_processor()
JobProcessorFactory::create_low_latency_processor()

// Transactional mode
JobProcessorFactory::create_transactional()

// Adaptive mode
JobProcessorFactory::create_adaptive_default()
JobProcessorFactory::create_adaptive_with_partitions(8)
JobProcessorFactory::create_adaptive_test_optimized(Some(4))

// From config string
JobProcessorFactory::create_from_str("simple") ?
JobProcessorFactory::create_from_str("transactional") ?
JobProcessorFactory::create_from_str("adaptive:8:affinity") ?
```

---

## Summary

### Quick Start Recommendation

**For 95% of use cases:**

```sql
WITH ('mode' = 'transactional')
```

‚úÖ Best performance (961K rec/sec on ROWS WINDOW)
‚úÖ ACID guarantees
‚úÖ At-least-once delivery
‚úÖ Handles all failure scenarios
‚úÖ Suitable for financial and critical data

### Configuration Checklist

- [ ] Determine if ACID is required
- [ ] Select processor type (Simple, Transactional, or Adaptive)
- [ ] Choose performance profile (throughput, conservative, low-latency)
- [ ] Set batch size based on latency requirements
- [ ] Configure failure strategy
- [ ] Enable/disable DLQ based on debugging needs
- [ ] Test with representative data
- [ ] Monitor actual throughput and adjust batch size

### When to Revisit Configuration

- **Throughput dropping:** Increase `max_batch_size`
- **Latency too high:** Decrease `batch_timeout` and `max_batch_size`
- **Too many failures:** Enable more `max_retries` and DLQ
- **Excessive logging:** Decrease `progress_interval` or disable `log_progress`
- **Slow data source:** Increase `empty_batch_count`

---

## Related Documentation

### Decision & Strategy Guides

- **[Job Processor Selection Guide](../../developer/job-processor-selection-guide.md)** - High-level guidance on when to
  use each processor
    - Quick decision matrix for common use cases
    - Performance comparisons and benchmarks
    - Migration strategies between processors
    - Partition handling and affinity management

### Configuration & Implementation Guides

- [Failure Strategy Guide](../developer/failure-strategies.md) - Detailed failure handling strategies
- [Dead Letter Queue Configuration](dlq-configuration-guide.md) - DLQ setup and usage
- [Observability & Metrics](../developer/observability.md) - Monitoring processor behavior
- [Performance Tuning](../developer/performance-tuning.md) - Optimization techniques
