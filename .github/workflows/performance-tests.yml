name: Performance Tests

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  schedule:
    # Run performance tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  CARGO_TERM_COLOR: always
  CARGO_INCREMENTAL: 0  # Disable incremental compilation for CI
  CARGO_PROFILE_DEV_DEBUG: 0  # Reduce debug info size
  RUST_BACKTRACE: 1

# Add permissions for the workflow to comment on PRs
permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  performance-tests:
    runs-on: ubuntu-latest
    
    services:
      kafka:
        image: confluentinc/cp-kafka:7.9.1
        env:
          KAFKA_NODE_ID: 1
          KAFKA_PROCESS_ROLES: "broker,controller"
          KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://kafka:29093"
          KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://localhost:9092"
          KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:29093"
          KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
          KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT"
          CLUSTER_ID: "citest123456789012345678901"
          KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
          KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
          KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
          KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
          KAFKA_LOG_DIRS: "/tmp/kraft-combined-logs"
        ports:
          - 9092:9092
          - 29093:29093
        options: >-
          --health-cmd "kafka-topics --bootstrap-server localhost:9092 --list"
          --health-interval 15s
          --health-timeout 10s
          --health-retries 10

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup Rust Environment
      uses: ./.github/actions/setup-rust
      with:
        rust-version: stable
        components: rustfmt,clippy
        cache-suffix: performance
    
    - name: Wait for Kafka (KRaft)
      run: |
        echo "Waiting for Kafka KRaft to be ready..."
        timeout 120 bash -c 'until nc -z localhost 9092; do sleep 2; done'
        echo "Kafka port is open, waiting for cluster to be ready..."
        sleep 15
        echo "Kafka KRaft is ready!"
    
    - name: Run JSON Performance Test
      run: |
        echo "Running JSON Performance Test..."
        cargo run --release --example json_performance_test > json_perf_results.txt 2>&1
        cat json_perf_results.txt
        echo "Waiting 45 seconds before next performance test..."
        sleep 45
    
    - name: Run Raw Bytes Performance Test
      run: |
        echo "Running Raw Bytes Performance Test..."
        cargo run --release --example raw_bytes_performance_test > raw_perf_results.txt 2>&1
        cat raw_perf_results.txt
        echo "Waiting 45 seconds before next performance test..."
        sleep 45
    
    - name: Run Latency Performance Test
      run: |
        echo "Running Latency Performance Test..."
        cargo run --release --example latency_performance_test > latency_perf_results.txt 2>&1
        cat latency_perf_results.txt
        echo "Waiting 45 seconds before next performance test..."
        sleep 45
    
    - name: Run Resource Monitoring Test
      run: |
        echo "Running Resource Monitoring Test..."
        cargo run --release --example resource_monitoring_test > resource_perf_results.txt 2>&1
        cat resource_perf_results.txt

    - name: Run FerrisStreams SQL Performance Benchmarks
      run: |
        echo "🔍 ENHANCED DEBUG: Running FerrisStreams SQL Performance Benchmarks..."
        echo "🏁 Environment: CI=$CI, GITHUB_ACTIONS=$GITHUB_ACTIONS"
        echo "⏰ Timestamp: $(date)"
        echo "💻 System Resources:"
        echo "  - CPU Info: $(nproc) cores"
        echo "  - Memory: $(free -h | grep Mem: | awk '{print $2}')"
        echo "  - Disk space: $(df -h / | tail -1 | awk '{print $4}')"
        echo "These benchmarks will run in CI mode with reduced dataset sizes"
        
        export CI=true
        export GITHUB_ACTIONS=true
        export RUST_BACKTRACE=1
        
        # Test Kafka connectivity before benchmarks
        echo "🔌 Testing Kafka connectivity..."
        timeout 10 bash -c 'until nc -z localhost 9092; do echo "Kafka not ready, waiting..."; sleep 2; done' && echo "✅ Kafka is ready" || echo "⚠️ Kafka connectivity test failed"
        
        # Initialize result file with header
        echo "=== FerrisStreams SQL Performance Benchmark Results ===" > ferris_sql_benchmarks.txt
        echo "Execution started at: $(date)" >> ferris_sql_benchmarks.txt
        echo "" >> ferris_sql_benchmarks.txt
        
        # Run ferris_sql_multi_benchmarks with enhanced error handling (run tests individually)
        echo "🧪 Running ferris_sql_multi_benchmarks..."
        echo "Note: Running tests individually due to cargo test syntax limitations"
        
        # Run comprehensive benchmark suite that outputs the summary format expected by metrics extraction
        echo "📊 Running run_comprehensive_benchmark_suite..."
        echo "Command: timeout 300 cargo test --no-default-features run_comprehensive_benchmark_suite -- --nocapture"
        START_TIME=$(date +%s)
        BENCHMARK_EXIT_CODE=0
        timeout 300 cargo test --no-default-features run_comprehensive_benchmark_suite -- --nocapture >> ferris_sql_benchmarks.txt 2>&1 || BENCHMARK_EXIT_CODE=$?
        END_TIME=$(date +%s)
        echo "📊 run_comprehensive_benchmark_suite completed with exit code: $BENCHMARK_EXIT_CODE (${END_TIME} - ${START_TIME} = $((END_TIME - START_TIME))s)"

        # Set aggregation exit code same as benchmark for compatibility
        AGGREGATION_EXIT_CODE=$BENCHMARK_EXIT_CODE
        
        # Combine exit codes for overall status
        OVERALL_EXIT_CODE=0
        if [ $BENCHMARK_EXIT_CODE -ne 0 ] || [ $AGGREGATION_EXIT_CODE -ne 0 ]; then
          OVERALL_EXIT_CODE=1
        fi
        
        echo "📊 ferris_sql_multi_benchmarks overall status: $OVERALL_EXIT_CODE"
        
        if [ $BENCHMARK_EXIT_CODE -eq 124 ] || [ $AGGREGATION_EXIT_CODE -eq 124 ]; then
          echo "⏰ ferris_sql_multi_benchmarks TIMED OUT (300s limit exceeded)"
          echo "TIMEOUT: ferris_sql_multi_benchmarks exceeded 300 second limit" >> ferris_sql_benchmarks.txt
        elif [ $OVERALL_EXIT_CODE -ne 0 ]; then
          echo "❌ ferris_sql_multi_benchmarks FAILED (baseline: $BENCHMARK_EXIT_CODE, aggregation: $AGGREGATION_EXIT_CODE)"
          echo "FAILURE: ferris_sql_multi_benchmarks failed (baseline: $BENCHMARK_EXIT_CODE, aggregation: $AGGREGATION_EXIT_CODE)" >> ferris_sql_benchmarks.txt
        else
          echo "✅ ferris_sql_multi_benchmarks completed successfully"
        fi
        
        echo "📄 Checking ferris_sql_benchmarks.txt output..."
        if [ -f ferris_sql_benchmarks.txt ]; then
          FILE_SIZE=$(wc -l < ferris_sql_benchmarks.txt)
          echo "✅ ferris_sql_benchmarks.txt exists, size: $FILE_SIZE lines"
          echo "📝 Last 10 lines of output:"
          tail -10 ferris_sql_benchmarks.txt | sed 's/^/    /'
        else
          echo "❌ ferris_sql_benchmarks.txt NOT CREATED"
          touch ferris_sql_benchmarks.txt
        fi
        
        # Run transactional processor benchmarks with enhanced error handling
        echo ""
        echo "🧪 Running transactional_processor_benchmarks..."
        echo "Command: timeout 300 cargo test --no-default-features benchmark_simple_vs_transactional_small_batch -- --ignored --nocapture"
        
        START_TIME=$(date +%s)
        PROCESSOR_EXIT_CODE=0
        timeout 300 cargo test --no-default-features \
          benchmark_simple_vs_transactional_small_batch \
          -- --ignored --nocapture >> ferris_sql_benchmarks.txt 2>&1 || PROCESSOR_EXIT_CODE=$?
        END_TIME=$(date +%s)
        
        echo "📊 transactional_processor_benchmarks completed with exit code: $PROCESSOR_EXIT_CODE"
        echo "⏱️ Execution time: $((END_TIME - START_TIME)) seconds"
        
        if [ $PROCESSOR_EXIT_CODE -eq 124 ]; then
          echo "⏰ transactional_processor_benchmarks TIMED OUT (300s limit exceeded)"
          echo "TIMEOUT: transactional_processor_benchmarks exceeded 300 second limit" >> ferris_sql_benchmarks.txt
        elif [ $PROCESSOR_EXIT_CODE -ne 0 ]; then
          echo "❌ transactional_processor_benchmarks FAILED with exit code $PROCESSOR_EXIT_CODE"
          echo "FAILURE: transactional_processor_benchmarks failed with exit code $PROCESSOR_EXIT_CODE" >> ferris_sql_benchmarks.txt
        else
          echo "✅ transactional_processor_benchmarks completed successfully"
        fi
        
        # Final results analysis
        echo ""
        echo "🏁 FerrisStreams SQL benchmarks completed"
        echo "📄 Final ferris_sql_benchmarks.txt analysis:"
        if [ -f ferris_sql_benchmarks.txt ]; then
          FILE_SIZE=$(wc -l < ferris_sql_benchmarks.txt)
          echo "  📝 Total lines: $FILE_SIZE"
          echo "  📊 Key metrics found:"
          echo "    - Baseline Throughput lines: $(grep -c "- Baseline Throughput:" ferris_sql_benchmarks.txt || echo "0")"
          echo "    - Aggregation Throughput lines: $(grep -c "- Aggregation Throughput:" ferris_sql_benchmarks.txt || echo "0")"
          echo "    - Simple/Transactional Processor lines: $(grep -c "Processor.*records/sec" ferris_sql_benchmarks.txt || echo "0")"
          echo "    - Error/timeout indicators: $(grep -c -E "(TIMEOUT|FAILURE|failed|timed out)" ferris_sql_benchmarks.txt || echo "0")"
          
          echo ""
          echo "=== FerrisStreams SQL Benchmark Results (Key Lines) ==="
          cat ferris_sql_benchmarks.txt | grep -E "(BASELINE|AGGREGATION|PROCESSOR|records/sec|✅|❌|Config:|TIMEOUT|FAILURE)" || echo "No key metrics found"
        else
          echo "  ❌ ferris_sql_benchmarks.txt does not exist!"
        fi
    
    - name: Extract Performance Metrics
      run: |
        echo "🔍 ENHANCED DEBUG: Extracting performance metrics..."
        
        # Debug: Show relevant lines from results files
        echo "=== JSON Performance Results (Messages Sent lines) ==="
        grep "Messages Sent" json_perf_results.txt || echo "No 'Messages Sent' lines found in json_perf_results.txt"
        
        echo "=== Raw Performance Results (Messages Sent lines) ==="
        grep "Messages Sent" raw_perf_results.txt || echo "No 'Messages Sent' lines found in raw_perf_results.txt"
        
        echo "=== Latency Performance Results (P95 Latency lines) ==="
        grep "P95 Latency" latency_perf_results.txt || echo "No 'P95 Latency' lines found in latency_perf_results.txt"
        
        # Extract JSON throughput (matches format: "Messages Sent:     12345 (123.4 msg/s)")
        JSON_THROUGHPUT=$(grep -oP 'Messages Sent:\s+\d+\s+\(\K\d+\.\d+(?=\s+msg/s\))' json_perf_results.txt | head -1 || echo "0")
        
        # Extract Raw throughput (matches format: "Messages Sent:     12345 (123.4 msg/s)")
        RAW_THROUGHPUT=$(grep -oP 'Messages Sent:\s+\d+\s+\(\K\d+\.\d+(?=\s+msg/s\))' raw_perf_results.txt | head -1 || echo "0")
        
        # Extract P95 latency (matches format: "   P95 Latency:       123.4 ms")
        P95_LATENCY=$(grep -oP 'P95 Latency:\s+\K\d+\.\d+(?=\s+ms)' latency_perf_results.txt | head -1 || echo "999")
        
        # Enhanced FerrisStreams SQL benchmark metrics extraction with comprehensive debugging
        echo ""
        echo "🔍 ENHANCED DEBUG: FerrisStreams SQL Benchmark Analysis"
        echo "======================================================="
        
        if [ -f ferris_sql_benchmarks.txt ]; then
          FILE_SIZE=$(wc -l < ferris_sql_benchmarks.txt)
          echo "✅ ferris_sql_benchmarks.txt exists (${FILE_SIZE} lines)"
          
          # Show full file content for debugging (first 50 lines)
          echo "📄 ferris_sql_benchmarks.txt content (first 50 lines):"
          head -50 ferris_sql_benchmarks.txt | sed 's/^/    /' || echo "Failed to read file"
          
          echo ""
          echo "🔍 Searching for performance metrics patterns:"
          
          # Search for all potential throughput patterns
          echo "  📊 All 'records/sec' lines:"
          grep "records/sec" ferris_sql_benchmarks.txt | sed 's/^/    /' || echo "    No 'records/sec' lines found"
          
          echo "  📊 All 'Throughput' lines:"
          grep -i "throughput" ferris_sql_benchmarks.txt | sed 's/^/    /' || echo "    No 'Throughput' lines found"
          
          echo "  📊 All 'Baseline' lines:"
          grep -i "baseline" ferris_sql_benchmarks.txt | sed 's/^/    /' || echo "    No 'Baseline' lines found"
          
          echo "  📊 All 'Aggregation' lines:"
          grep -i "aggregation" ferris_sql_benchmarks.txt | sed 's/^/    /' || echo "    No 'Aggregation' lines found"
          
          echo "  📊 All 'Processor' lines:"
          grep -i "processor" ferris_sql_benchmarks.txt | sed 's/^/    /' || echo "    No 'Processor' lines found"
          
          echo "  🚨 Error indicators:"
          grep -i -E "(timeout|failure|failed|error|timed out)" ferris_sql_benchmarks.txt | sed 's/^/    ⚠️ /' || echo "    No error indicators found"
          
          echo ""
          echo "🧮 Attempting metrics extraction..."
          
          # Extract baseline throughput with multiple patterns
          echo "  🔍 Extracting baseline throughput:"
          BASELINE_THROUGHPUT=""
          if grep -q "- Baseline Throughput:" ferris_sql_benchmarks.txt; then
            BASELINE_THROUGHPUT=$(grep "- Baseline Throughput:" ferris_sql_benchmarks.txt | grep -oE '[0-9]+' | head -1 || echo "0")
            echo "    ✅ Found '- Baseline Throughput:' pattern, extracted: $BASELINE_THROUGHPUT"
          elif grep -q -i "baseline.*records/sec" ferris_sql_benchmarks.txt; then
            BASELINE_THROUGHPUT=$(grep -i "baseline.*records/sec" ferris_sql_benchmarks.txt | grep -oE '[0-9]+(\.[0-9]+)?' | tail -1 | cut -d. -f1 || echo "0")
            echo "    ✅ Found alternative baseline pattern, extracted: $BASELINE_THROUGHPUT"
          else
            BASELINE_THROUGHPUT="0"
            echo "    ❌ No baseline throughput pattern found"
          fi
          
          # Extract aggregation throughput with multiple patterns
          echo "  🔍 Extracting aggregation throughput:"
          AGGREGATION_THROUGHPUT=""
          if grep -q "- Aggregation Throughput:" ferris_sql_benchmarks.txt; then
            AGGREGATION_THROUGHPUT=$(grep "- Aggregation Throughput:" ferris_sql_benchmarks.txt | grep -oE '[0-9]+' | head -1 || echo "0")
            echo "    ✅ Found '- Aggregation Throughput:' pattern, extracted: $AGGREGATION_THROUGHPUT"
          elif grep -q -i "aggregation.*records/sec" ferris_sql_benchmarks.txt; then
            AGGREGATION_THROUGHPUT=$(grep -i "aggregation.*records/sec" ferris_sql_benchmarks.txt | grep -oE '[0-9]+(\.[0-9]+)?' | tail -1 | cut -d. -f1 || echo "0")
            echo "    ✅ Found alternative aggregation pattern, extracted: $AGGREGATION_THROUGHPUT"
          else
            AGGREGATION_THROUGHPUT="0"
            echo "    ❌ No aggregation throughput pattern found"
          fi
          
          # Extract processor comparison with multiple patterns  
          echo "  🔍 Extracting processor comparison:"
          SIMPLE_THROUGHPUT=""
          TRANSACTIONAL_THROUGHPUT=""
          
          if grep -q "Simple Processor:" ferris_sql_benchmarks.txt; then
            SIMPLE_THROUGHPUT=$(grep "Simple Processor:" ferris_sql_benchmarks.txt | grep -oE '[0-9]+' | tail -1 || echo "0")
            echo "    ✅ Found Simple Processor, extracted: $SIMPLE_THROUGHPUT"
          else
            SIMPLE_THROUGHPUT="0"
            echo "    ❌ No Simple Processor pattern found"
          fi
          
          if grep -q "Transactional Processor:" ferris_sql_benchmarks.txt; then
            TRANSACTIONAL_THROUGHPUT=$(grep "Transactional Processor:" ferris_sql_benchmarks.txt | grep -oE '[0-9]+' | tail -1 || echo "1")
            echo "    ✅ Found Transactional Processor, extracted: $TRANSACTIONAL_THROUGHPUT"
          else
            TRANSACTIONAL_THROUGHPUT="1"
            echo "    ❌ No Transactional Processor pattern found"
          fi
          
          # Calculate processor ratio safely
          if [ "$TRANSACTIONAL_THROUGHPUT" != "0" ] && [ "$SIMPLE_THROUGHPUT" != "0" ] && command -v bc >/dev/null 2>&1; then
            PROCESSOR_RATIO=$(echo "scale=1; $SIMPLE_THROUGHPUT / $TRANSACTIONAL_THROUGHPUT" | bc 2>/dev/null || echo "1.0")
            echo "    🧮 Calculated processor ratio: ${SIMPLE_THROUGHPUT}/${TRANSACTIONAL_THROUGHPUT} = $PROCESSOR_RATIO"
          else
            PROCESSOR_RATIO="1.0"
            echo "    ⚠️ Using default processor ratio: $PROCESSOR_RATIO (bc missing or zero values)"
          fi
          
        else
          echo "❌ ferris_sql_benchmarks.txt file does not exist!"
          BASELINE_THROUGHPUT="0"
          AGGREGATION_THROUGHPUT="0" 
          PROCESSOR_RATIO="1.0"
        fi
        
        echo ""
        echo "📈 Final extracted values:"
        echo "  - Baseline Throughput: $BASELINE_THROUGHPUT records/sec"
        echo "  - Aggregation Throughput: $AGGREGATION_THROUGHPUT records/sec"
        echo "  - Processor Ratio: $PROCESSOR_RATIO"
        
        echo "JSON_THROUGHPUT=$JSON_THROUGHPUT" >> $GITHUB_ENV
        echo "RAW_THROUGHPUT=$RAW_THROUGHPUT" >> $GITHUB_ENV  
        echo "P95_LATENCY=$P95_LATENCY" >> $GITHUB_ENV
        echo "BASELINE_THROUGHPUT=$BASELINE_THROUGHPUT" >> $GITHUB_ENV
        echo "AGGREGATION_THROUGHPUT=$AGGREGATION_THROUGHPUT" >> $GITHUB_ENV
        echo "PROCESSOR_RATIO=$PROCESSOR_RATIO" >> $GITHUB_ENV
        
        echo ""
        echo "🎯 FINAL PERFORMANCE METRICS SUMMARY:"
        echo "====================================="
        echo "Kafka Streaming Performance:"
        echo "  JSON Throughput: $JSON_THROUGHPUT msg/s"
        echo "  Raw Throughput: $RAW_THROUGHPUT msg/s"
        echo "  P95 Latency: $P95_LATENCY ms"
        echo ""
        echo "FerrisStreams SQL Performance:"
        echo "  SQL Baseline Throughput: $BASELINE_THROUGHPUT records/sec"
        echo "  SQL Aggregation Throughput: $AGGREGATION_THROUGHPUT records/sec"
        echo "  Processor Performance Ratio: ${PROCESSOR_RATIO}x faster"
        echo ""
        echo "🚨 DIAGNOSTIC STATUS:"
        if [ "$BASELINE_THROUGHPUT" = "0" ] && [ "$AGGREGATION_THROUGHPUT" = "0" ]; then
          echo "  ❌ SQL benchmarks failed to complete (likely timeout/infrastructure issues)"
          echo "  ✅ Kafka streaming benchmarks completed successfully"
          echo "  💡 This explains why SQL metrics show ❌ in the workflow summary"
        else
          echo "  ✅ All benchmarks completed successfully"
        fi
    
    - name: Performance Regression Check
      run: |
        echo "Checking for performance regressions..."
        
        # Define minimum acceptable performance thresholds
        MIN_JSON_THROUGHPUT=100
        MIN_RAW_THROUGHPUT=100
        MAX_P95_LATENCY=100
        
        # Check JSON throughput
        if (( $(echo "$JSON_THROUGHPUT < $MIN_JSON_THROUGHPUT" | bc -l) )); then
          echo "❌ JSON throughput regression: $JSON_THROUGHPUT < $MIN_JSON_THROUGHPUT msg/s"
          exit 1
        fi
        
        # Check Raw throughput
        if (( $(echo "$RAW_THROUGHPUT < $MIN_RAW_THROUGHPUT" | bc -l) )); then
          echo "❌ Raw throughput regression: $RAW_THROUGHPUT < $MIN_RAW_THROUGHPUT msg/s"
          exit 1
        fi
        
        # Check P95 latency
        if (( $(echo "$P95_LATENCY > $MAX_P95_LATENCY" | bc -l) )); then
          echo "❌ Latency regression: $P95_LATENCY > $MAX_P95_LATENCY ms"
          exit 1
        fi
        
        # Check SQL performance thresholds (more realistic for CI)
        MIN_SQL_BASELINE=10
        MIN_SQL_AGGREGATION=5
        MIN_PROCESSOR_RATIO=1.5
        
        # Check SQL baseline throughput (warn only if SQL benchmarks failed to run)
        if [ "$BASELINE_THROUGHPUT" = "0" ]; then
          echo "⚠️ SQL baseline benchmarks did not run - this is expected in some CI environments"
        elif (( $(echo "$BASELINE_THROUGHPUT < $MIN_SQL_BASELINE" | bc -l) )); then
          echo "❌ SQL baseline regression: $BASELINE_THROUGHPUT < $MIN_SQL_BASELINE records/sec"
          exit 1
        else
          echo "✅ SQL baseline performance: $BASELINE_THROUGHPUT records/sec"
        fi
        
        # Check SQL aggregation throughput (warn only if SQL benchmarks failed to run)
        if [ "$AGGREGATION_THROUGHPUT" = "0" ]; then
          echo "⚠️ SQL aggregation benchmarks did not run - this is expected in some CI environments"
        elif (( $(echo "$AGGREGATION_THROUGHPUT < $MIN_SQL_AGGREGATION" | bc -l) )); then
          echo "❌ SQL aggregation regression: $AGGREGATION_THROUGHPUT < $MIN_SQL_AGGREGATION records/sec"
          exit 1
        else
          echo "✅ SQL aggregation performance: $AGGREGATION_THROUGHPUT records/sec"
        fi
        
        # Check processor performance ratio (warn only if processor benchmarks failed to run)
        if [ "$PROCESSOR_RATIO" = "1.0" ] && [ "$SIMPLE_THROUGHPUT" = "0" ]; then
          echo "⚠️ Processor comparison benchmarks did not run - this is expected in some CI environments"
        elif (( $(echo "$PROCESSOR_RATIO < $MIN_PROCESSOR_RATIO" | bc -l) )); then
          echo "❌ Processor performance regression: ${PROCESSOR_RATIO}x < ${MIN_PROCESSOR_RATIO}x improvement"
          exit 1
        else
          echo "✅ Processor performance ratio: ${PROCESSOR_RATIO}x"
        fi
        
        echo "✅ All performance checks passed!"

    - name: Upload Performance Results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-results
        path: |
          json_perf_results.txt
          raw_perf_results.txt
          latency_perf_results.txt
          resource_perf_results.txt
          ferris_sql_benchmarks.txt
    
    - name: Comment Performance Results (PR only)
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const jsonThroughput = process.env.JSON_THROUGHPUT;
          const rawThroughput = process.env.RAW_THROUGHPUT;
          const p95Latency = process.env.P95_LATENCY;
          const baselineThroughput = process.env.BASELINE_THROUGHPUT;
          const aggregationThroughput = process.env.AGGREGATION_THROUGHPUT;
          const processorRatio = process.env.PROCESSOR_RATIO;
          
          const comment = `## 📊 Performance Test Results
          
          ### Kafka Streaming Performance
          | Metric | Value | Status |
          |--------|-------|--------|
          | JSON Throughput | ${jsonThroughput} msg/s | ${jsonThroughput > 1000 ? '✅' : '❌'} |
          | Raw Throughput | ${rawThroughput} msg/s | ${rawThroughput > 5000 ? '✅' : '❌'} |
          | P95 Latency | ${p95Latency} ms | ${p95Latency < 100 ? '✅' : '❌'} |
          
          ### FerrisStreams SQL Performance
          | Metric | Value | Status |
          |--------|-------|--------|
          | SQL Baseline | ${baselineThroughput} records/sec | ${baselineThroughput > 50 ? '✅' : '❌'} |
          | SQL Aggregation | ${aggregationThroughput} records/sec | ${aggregationThroughput > 10 ? '✅' : '❌'} |
          | Processor Improvement | ${processorRatio}x faster | ${processorRatio > 5.0 ? '✅' : '❌'} |
          
          Performance tests completed automatically. Check the [workflow run](${context.payload.pull_request.html_url}/checks) for detailed results.`;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });